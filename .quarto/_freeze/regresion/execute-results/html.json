{
  "hash": "b09ad433c25c97b29d39680b3a644a96",
  "result": {
    "markdown": "---\ntitle: \"Regresión\"\n---\n\n::: {.cell}\n\n```{.r .cell-code}\n# Librerías, datasets y procesamiento previo\nlibrary(readr)\nlibrary(dplyr)\nlibrary(fcaR)\nlibrary(magrittr)\nlibrary(ggplot2)\nlibrary(psych)\nlibrary(arules)\n\ndatos <- read_csv(\"train.csv\")\nView(datos)\ndatos_test <- read_csv(\"test.csv\")\nView(datos_test)\n\ndatos <- rename(datos, profile_pic=`profile pic`, `nums/length_username` = `nums/length username`, fullname_words=`fullname words`, `nums/length_fullname` = `nums/length fullname`, description_length=`description length`, external_URL=`external URL`, posts=`#posts`, followers=`#followers`, follows=`#follows`)\n\ndatos_test <- rename(datos_test, profile_pic=`profile pic`, `nums/length_username` = `nums/length username`, fullname_words=`fullname words`, `nums/length_fullname` = `nums/length fullname`, description_length=`description length`, external_URL=`external URL`, posts=`#posts`, followers=`#followers`, follows=`#follows`)\n```\n:::\n\n\n## Regresión\n\nUna vez visto el Formal Concept Analysis, ahora es el turno de la regresión: analizar la relación entre una variable dependiente (variable objetivo o respuesta) y ciertas variables independientes (variable predictora o explicativa).\n\n### Modelos multi-variable\n\nEn nuestro caso, la variable dependiente será 'fake', y trataremos de encontrar el mejor modelo para explicar la variable dependiente.\n\nPrimero, realicemos un plot de los datos para intentar encontrar relaciones visuales:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(datos)\n```\n\n::: {.cell-output-display}\n![](regresion_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\nSe observa que, lógicamente, es imposible extraer información visual de la relación entre 'fake' y las demás variables binarias, ya que aparecen 4 puntos en las esquinas (las 4 posibles combinaciones). Sin embargo, las variables numéricas son más reveladoras. Por ejemplo, se nota que en posts y followers hay más cuentas fake cuando estas variables tienen valores bajos.\n\nPodemos osbervar un mejor gráfico quitando las variables binarias:\n\n\n::: {.cell}\n\n```{.r .cell-code}\npairs.panels(datos[c(\"profile_pic\",\"nums/length_username\",\"fullname_words\",\"nums/length_fullname\",\"description_length\",\"posts\",\"followers\",\"follows\",\"fake\")])\n```\n\n::: {.cell-output-display}\n![](regresion_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\nQueda claro que es necesario un análisis numérico. Comencemos por construir un modelo lineal con todas las variables posibles como independientes:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodelo1 <- lm(fake ~ .,\n              data = datos)\n\nsummary(modelo1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = fake ~ ., data = datos)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.73096 -0.23729 -0.06653  0.24048  1.01052 \n\nCoefficients:\n                         Estimate Std. Error t value Pr(>|t|)    \n(Intercept)             7.931e-01  3.798e-02  20.880  < 2e-16 ***\nprofile_pic            -4.380e-01  3.345e-02 -13.094  < 2e-16 ***\n`nums/length_username`  8.062e-01  7.522e-02  10.718  < 2e-16 ***\nfullname_words         -3.354e-02  1.333e-02  -2.516 0.012142 *  \n`nums/length_fullname` -2.775e-02  1.212e-01  -0.229 0.818988    \n`name==username`        2.241e-01  7.641e-02   2.933 0.003498 ** \ndescription_length     -1.510e-03  4.342e-04  -3.478 0.000544 ***\nexternal_URL           -1.542e-01  4.800e-02  -3.213 0.001390 ** \nprivate                -9.459e-03  2.843e-02  -0.333 0.739459    \nposts                  -9.094e-05  3.570e-05  -2.547 0.011120 *  \nfollowers              -9.960e-09  1.539e-08  -0.647 0.517743    \nfollows                -1.850e-05  1.499e-05  -1.235 0.217530    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.3166 on 564 degrees of freedom\nMultiple R-squared:  0.6074,\tAdjusted R-squared:  0.5998 \nF-statistic: 79.33 on 11 and 564 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\nAnalicemos la salida:\n\n-   Un intercept de 0,7931 indica que ese es el valor medio de la variable dependiente ('fake') cuando las variables independientes son cero.\n-   profile_pic: es muy significativa, con el valor estimado negativo, es decir, tener una foto de perfil disminuye la probabilidad de ser una cuenta falsa.\n-   nums/length_username: es muy significativa, con un valor estimado de positivo, es decir, un mayor ratio de caracteres numéricos en el nombre de usuario aumenta la probabilidad de ser una cuenta falsa.\n-   fullname_words: es algo significativa, con un valor estimado negativo, es decir, un mayor número de palabras en el nombre completo disminuye ligeramente la probabilidad de ser una cuenta falsa.\n-   nums/length_fullname: no es significativa. Su variación no influye notablemente en la probabilidad de que la cuenta sea falsa.\n-   name==username: es significativa, con un valor estimado positivo, es decir, si el nombre completo y el nombre de usuario son iguales, aumenta la probabilidad de ser una cuenta falsa.\n-   description_length: es muy significativa, con un valor estimado negativo, es decir, una mayor longitud de la descripción disminuye la probabilidad de ser una cuenta falsa.\n-   external_URL: es significativa, con un valor estimado negativo, es decir, tener una URL externa disminuye la probabilidad de ser una cuenta falsa.\n-   private: no es significativa. Su variación no influye notablemente en la probabilidad de que la cuenta sea falsa.\n-   posts: es significativa, con un valor estimado negativo, es decir, un mayor número de publicaciones disminuye la probabilidad de ser una cuenta falsa.\n-   followers: no es significativa. Su variación no influye notablemente en la probabilidad de que la cuenta sea falsa.\n-   follows: no es significativa. Su variación no influye notablemente en la probabilidad de que la cuenta sea falsa.\n\nEsta información nos será útil para la construcción de modelos útiles, que tengan en cuenta las variables más significativas.\n\nProbemos a construir un modelo lineal que deseche las variables no significativas:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodelo2 <- lm(fake ~ profile_pic + `nums/length_username` + fullname_words + `name==username` + description_length + external_URL + posts, \n              data = datos)\n\nsummary(modelo2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = fake ~ profile_pic + `nums/length_username` + fullname_words + \n    `name==username` + description_length + external_URL + posts, \n    data = datos)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.74953 -0.24241 -0.05836  0.23371  1.02834 \n\nCoefficients:\n                         Estimate Std. Error t value Pr(>|t|)    \n(Intercept)             7.843e-01  3.577e-02  21.926  < 2e-16 ***\nprofile_pic            -4.444e-01  3.267e-02 -13.603  < 2e-16 ***\n`nums/length_username`  8.084e-01  6.861e-02  11.783  < 2e-16 ***\nfullname_words         -3.353e-02  1.326e-02  -2.528 0.011728 *  \n`name==username`        2.157e-01  7.265e-02   2.969 0.003116 ** \ndescription_length     -1.553e-03  4.283e-04  -3.625 0.000315 ***\nexternal_URL           -1.528e-01  4.747e-02  -3.219 0.001359 ** \nposts                  -9.923e-05  3.369e-05  -2.945 0.003360 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.316 on 568 degrees of freedom\nMultiple R-squared:  0.606,\tAdjusted R-squared:  0.6012 \nF-statistic: 124.8 on 7 and 568 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\nExpliquemos los resultados generales y la mejora de este modelo con respecto al anterior:\n\n-   Residual Standard Error: el error estándar residual mide la dispersión de los residuos. Una disminución en el segundo modelo (0,316) indica una ligera mejora en la precisión de las predicciones del modelo simplificado.\n-   Multiple R-squared: el R-cuadrado múltiple mide la proporción de la variabilidad en la variable dependiente que es explicada por las variables independientes. Ambos modelos tienen valores similares, con una ligera disminución en el segundo modelo (0,606), lo que indica que se ha perdido ligeramente esa capacidad explicativa de las variables independientes.\n-   Adjusted R-squared: el R-cuadrado ajustado tiene en cuenta el número de variables en el modelo y penaliza la inclusión de variables irrelevantes. El aumento en el R-cuadrado ajustado en el segundo modelo (0,6012) sugiere que el modelo simplificado es más eficiente al explicar la variabilidad de la variable dependiente con menos variables.\n-   F-Statistic: la F-estadística mide la relación entre la variabilidad explicada y la variabilidad no explicada del modelo. Un valor más alto en el segundo modelo (124,8) indica que el modelo simplificado tiene un ajuste global mejor y es más significativo.\n-   p-value: el valor p indica la significancia general del modelo. En ambos casos, el valor p es extremadamente pequeño, lo que significa que ambos modelos son altamente significativos.\n\nProbemos un modelo en el que las variables con mayor nivel de significancia estén al cuadrado:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodelo3 <- lm(fake ~ I(profile_pic^2) + I(`nums/length_username`^2) + fullname_words + `name==username` + I(description_length^2) + external_URL + posts, \n              data = datos)\n\nsummary(modelo3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = fake ~ I(profile_pic^2) + I(`nums/length_username`^2) + \n    fullname_words + `name==username` + I(description_length^2) + \n    external_URL + posts, data = datos)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.88443 -0.28449 -0.03917  0.14543  0.91792 \n\nCoefficients:\n                              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)                  9.009e-01  3.437e-02  26.214  < 2e-16 ***\nI(profile_pic^2)            -5.140e-01  3.351e-02 -15.337  < 2e-16 ***\nI(`nums/length_username`^2)  9.430e-01  1.062e-01   8.877  < 2e-16 ***\nfullname_words              -4.636e-02  1.400e-02  -3.312 0.000986 ***\n`name==username`             2.364e-01  7.722e-02   3.061 0.002311 ** \nI(description_length^2)     -5.231e-06  3.480e-06  -1.503 0.133362    \nexternal_URL                -2.288e-01  4.973e-02  -4.601  5.2e-06 ***\nposts                       -1.181e-04  3.572e-05  -3.305 0.001010 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.3358 on 568 degrees of freedom\nMultiple R-squared:  0.5553,\tAdjusted R-squared:  0.5498 \nF-statistic: 101.3 on 7 and 568 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\nEste modelo es peor que los anteriores en todos los parámetros generales.\n\nProbemos con un modelo lineal cuyas variables independientes son únicamente las 3 que en el primer modelo tenían más significancia:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodelo4 <- lm(fake ~ profile_pic + `nums/length_username` + description_length, \n              data = datos)\n\nsummary(modelo4)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = fake ~ profile_pic + `nums/length_username` + description_length, \n    data = datos)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.71251 -0.24060 -0.09454  0.25287  1.08855 \n\nCoefficients:\n                         Estimate Std. Error t value Pr(>|t|)    \n(Intercept)             0.7462368  0.0317943  23.471  < 2e-16 ***\nprofile_pic            -0.4758359  0.0331911 -14.336  < 2e-16 ***\n`nums/length_username`  0.8667753  0.0697244  12.431  < 2e-16 ***\ndescription_length     -0.0024090  0.0003966  -6.075 2.27e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.3255 on 572 degrees of freedom\nMultiple R-squared:  0.5791,\tAdjusted R-squared:  0.5769 \nF-statistic: 262.4 on 3 and 572 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\nEste modelo es el mejor por ahora. Ninguno le supera en los parámetros finales, excepto los 2 primeros modelos en el error.\n\nProbemos a elevar al cuadrado las dos variables que, en el primer modelo, eran las más significativas:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodelo5 <- lm(fake ~ I(profile_pic^2) + I(`nums/length_username`^2) + description_length, \n              data = datos)\n\nsummary(modelo5)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = fake ~ I(profile_pic^2) + I(`nums/length_username`^2) + \n    description_length, data = datos)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-0.8257 -0.2721 -0.0701  0.1341  1.0911 \n\nCoefficients:\n                              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)                  0.8658746  0.0298412  29.016  < 2e-16 ***\nI(profile_pic^2)            -0.5291041  0.0343600 -15.399  < 2e-16 ***\nI(`nums/length_username`^2)  0.9668541  0.1083190   8.926  < 2e-16 ***\ndescription_length          -0.0028714  0.0004144  -6.929 1.14e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.3437 on 572 degrees of freedom\nMultiple R-squared:  0.5308,\tAdjusted R-squared:  0.5283 \nF-statistic: 215.7 on 3 and 572 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\nLos resultados empeoran.\n\nParece difícil mejorar el modelo4. Probemos con un modelo que tenga en cuenta únicamente 2 variables más significativas del modelo1, pero sin cuadrados:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodelo6 <- lm(fake ~ profile_pic + `nums/length_username`, \n              data = datos)\n\nsummary(modelo6)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = fake ~ profile_pic + `nums/length_username`, data = datos)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-0.7170 -0.1838 -0.1838  0.2732  0.8162 \n\nCoefficients:\n                       Estimate Std. Error t value Pr(>|t|)    \n(Intercept)             0.71697    0.03240   22.13   <2e-16 ***\nprofile_pic            -0.53320    0.03280  -16.26   <2e-16 ***\n`nums/length_username`  0.95834    0.07018   13.66   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.3355 on 573 degrees of freedom\nMultiple R-squared:  0.552,\tAdjusted R-squared:  0.5504 \nF-statistic:   353 on 2 and 573 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\nEl F estadístico mejora, pero los demás parámetros empeoran ligeramente. Aun así, veo este modelo como el mejor, ya que el empeoramiento es muy leve, y el aumento del F estadístico es grande.\n\n### Modelos con una variable independiente (con visualización)\n\nComo acabamos de ver, eliminar variables independientes ha generado buenos resultados. Aunque dudo que encontremos un modelo mejor, aprovechemos para realizar modelos con una única variable independiente (probando con todas ellas y visualizando la predicción).\n\n#### Modelo con profile_pic como variable independiente:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodelo7 <- lm(fake ~ profile_pic, \n              data = datos)\n\nsummary(modelo7)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = fake ~ profile_pic, data = datos)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.98837 -0.29208 -0.14023  0.01163  0.70792 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  0.98837    0.02943   33.58   <2e-16 ***\nprofile_pic -0.69629    0.03514  -19.81   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.386 on 574 degrees of freedom\nMultiple R-squared:  0.4062,\tAdjusted R-squared:  0.4051 \nF-statistic: 392.6 on 1 and 574 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\nEl F estadístico mejora, pero los demás parámetros empeoran considerablemente.\n\nVeamos la predicción:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndatos %>%\n  ggplot(aes(x=profile_pic, y=fake)) + \n  geom_point() + \n  geom_line(aes(x=profile_pic, y=predict(modelo7),\n                color=\"red\"))\n```\n\n::: {.cell-output-display}\n![](regresion_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\nSin foto de perfil, hay más probabilidad de que la cuenta sea falsa.\n\n#### Modelo con nums/length_username como variable independiente:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodelo8 <- lm(fake ~ `nums/length_username`, \n              data = datos)\n\nsummary(modelo8)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = fake ~ `nums/length_username`, data = datos)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-0.8931 -0.2749 -0.2749  0.3130  0.7251 \n\nCoefficients:\n                       Estimate Std. Error t value Pr(>|t|)    \n(Intercept)             0.27494    0.02127   12.93   <2e-16 ***\n`nums/length_username`  1.37368    0.07894   17.40   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4052 on 574 degrees of freedom\nMultiple R-squared:  0.3454,\tAdjusted R-squared:  0.3442 \nF-statistic: 302.8 on 1 and 574 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\nVeamos la predicción:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndatos %>%\n  ggplot(aes(x=`nums/length_username`, y=fake)) + \n  geom_point() + \n  geom_line(aes(x=`nums/length_username`, y=predict(modelo8),\n                color=\"red\"))\n```\n\n::: {.cell-output-display}\n![](regresion_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n:::\n\n\nCon valores bajos de este ratio es menos probable que la cuenta sea falsa.\n\n#### Modelo con fullname_words como variable independiente:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodelo9 <- lm(fake ~ fullname_words, \n              data = datos)\n\nsummary(modelo9)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = fake ~ fullname_words, data = datos)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-0.7074 -0.4233  0.2926  0.4346  1.0029 \n\nCoefficients:\n               Estimate Std. Error t value Pr(>|t|)    \n(Intercept)     0.70741    0.03408  20.760  < 2e-16 ***\nfullname_words -0.14205    0.01894  -7.501 2.42e-13 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.478 on 574 degrees of freedom\nMultiple R-squared:  0.08928,\tAdjusted R-squared:  0.08769 \nF-statistic: 56.27 on 1 and 574 DF,  p-value: 2.418e-13\n```\n:::\n:::\n\n\nVeamos la predicción:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndatos %>%\n  ggplot(aes(x=fullname_words, y=fake)) + \n  geom_point() + \n  geom_line(aes(x=fullname_words, y=predict(modelo9),\n                color=\"red\"))\n```\n\n::: {.cell-output-display}\n![](regresion_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n:::\n\n\nCon mayores bajos de fullname_words es más probable que la cuenta sea falsa.\n\n#### Modelo con name==username como variable independiente:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodelo10 <- lm(fake ~ `name==username`, \n              data = datos)\n\nsummary(modelo10)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = fake ~ `name==username`, data = datos)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-0.9500 -0.4838 -0.2169  0.5162  0.5162 \n\nCoefficients:\n                 Estimate Std. Error t value Pr(>|t|)    \n(Intercept)       0.48381    0.02093   23.12  < 2e-16 ***\n`name==username`  0.46619    0.11232    4.15 3.82e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4935 on 574 degrees of freedom\nMultiple R-squared:  0.02914,\tAdjusted R-squared:  0.02745 \nF-statistic: 17.23 on 1 and 574 DF,  p-value: 3.821e-05\n```\n:::\n:::\n\n\nVeamos la predicción:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndatos %>%\n  ggplot(aes(x=`name==username`, y=fake)) + \n  geom_point() + \n  geom_line(aes(x=`name==username`, y=predict(modelo10),\n                color=\"red\"))\n```\n\n::: {.cell-output-display}\n![](regresion_files/figure-html/unnamed-chunk-17-1.png){width=672}\n:::\n:::\n\n\nCuando la coincidencia de fullname y username está presente, es más probable que la cuenta sea falsa.\n\n#### Modelo con description_length como variable independiente:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodelo11 <- lm(fake ~ description_length, \n              data = datos)\n\nsummary(modelo11)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = fake ~ description_length, data = datos)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-0.6384 -0.4732  0.3204  0.3616  1.2730 \n\nCoefficients:\n                     Estimate Std. Error t value Pr(>|t|)    \n(Intercept)         0.6383765  0.0216050   29.55   <2e-16 ***\ndescription_length -0.0061166  0.0004917  -12.44   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4445 on 574 degrees of freedom\nMultiple R-squared:  0.2124,\tAdjusted R-squared:  0.211 \nF-statistic: 154.8 on 1 and 574 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\nVeamos la predicción:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndatos %>%\n  ggplot(aes(x=description_length, y=fake)) + \n  geom_point() + \n  geom_line(aes(x=description_length, y=predict(modelo11),\n                color=\"red\"))\n```\n\n::: {.cell-output-display}\n![](regresion_files/figure-html/unnamed-chunk-19-1.png){width=672}\n:::\n:::\n\n\nPara valores altos de description_length es menos probable que la cuenta sea falsa.\n\n#### Modelo con external_URL como variable independiente:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodelo12 <- lm(fake ~ external_URL, \n              data = datos)\n\nsummary(modelo12)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = fake ~ external_URL, data = datos)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-0.5658 -0.5658  0.2171  0.4342  0.4342 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   0.56582    0.02069  27.350   <2e-16 ***\nexternal_URL -0.56582    0.06066  -9.328   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4667 on 574 degrees of freedom\nMultiple R-squared:  0.1316,\tAdjusted R-squared:  0.1301 \nF-statistic: 87.01 on 1 and 574 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\nVeamos la predicción:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndatos %>%\n  ggplot(aes(x=external_URL, y=fake)) + \n  geom_point() + \n  geom_line(aes(x=external_URL, y=predict(modelo12),\n                color=\"red\"))\n```\n\n::: {.cell-output-display}\n![](regresion_files/figure-html/unnamed-chunk-21-1.png){width=672}\n:::\n:::\n\n\nPara valores 1 de URL externa, es menos probable que la cuenta sea falsa.\n\n#### Modelo con private como variable independiente:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodelo13 <- lm(fake ~ private, \n              data = datos)\n\nsummary(modelo13)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = fake ~ private, data = datos)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.51124 -0.51124  0.00347  0.48876  0.51818 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  0.51124    0.02654  19.266   <2e-16 ***\nprivate     -0.02942    0.04294  -0.685    0.494    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5007 on 574 degrees of freedom\nMultiple R-squared:  0.0008172,\tAdjusted R-squared:  -0.0009236 \nF-statistic: 0.4694 on 1 and 574 DF,  p-value: 0.4935\n```\n:::\n:::\n\n\nVeamos la predicción:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndatos %>%\n  ggplot(aes(x=private, y=fake)) + \n  geom_point() + \n  geom_line(aes(x=private, y=predict(modelo13),\n                color=\"red\"))\n```\n\n::: {.cell-output-display}\n![](regresion_files/figure-html/unnamed-chunk-23-1.png){width=672}\n:::\n:::\n\n\nComo ya señalamos en apartados anteriores, la variable private no determina notablemente si es más o menos probable que la cuenta sea falsa. Este gráfico lo respalda.\n\n#### Modelo con posts como variable independiente:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodelo14 <- lm(fake ~ posts, \n              data = datos)\n\nsummary(modelo14)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = fake ~ posts, data = datos)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-0.5328 -0.5102  0.4672  0.4672  1.7238 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  5.328e-01  2.094e-02  25.441  < 2e-16 ***\nposts       -3.054e-04  5.037e-05  -6.064 2.41e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4856 on 574 degrees of freedom\nMultiple R-squared:  0.0602,\tAdjusted R-squared:  0.05856 \nF-statistic: 36.77 on 1 and 574 DF,  p-value: 2.414e-09\n```\n:::\n:::\n\n\nVeamos la predicción:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndatos %>%\n  ggplot(aes(x=posts, y=fake)) + \n  geom_point() + \n  geom_line(aes(x=posts, y=predict(modelo14),\n                color=\"red\"))\n```\n\n::: {.cell-output-display}\n![](regresion_files/figure-html/unnamed-chunk-25-1.png){width=672}\n:::\n:::\n\n\nPara valores altos de publicaciones es menos probable que la cuenta sea falsa.\n\n#### Modelo con followers como variable independiente:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodelo15 <- lm(fake ~ followers, \n              data = datos)\n\nsummary(modelo15)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = fake ~ followers, data = datos)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-0.5044 -0.5044  0.3907  0.4956  0.4958 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  5.044e-01  2.087e-02  24.170   <2e-16 ***\nfollowers   -5.151e-08  2.285e-08  -2.255   0.0245 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4987 on 574 degrees of freedom\nMultiple R-squared:  0.008778,\tAdjusted R-squared:  0.007051 \nF-statistic: 5.083 on 1 and 574 DF,  p-value: 0.02454\n```\n:::\n:::\n\n\nVeamos la predicción:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndatos %>%\n  ggplot(aes(x=followers, y=fake)) + \n  geom_point() + \n  geom_line(aes(x=followers, y=predict(modelo15),\n                color=\"red\"))\n```\n\n::: {.cell-output-display}\n![](regresion_files/figure-html/unnamed-chunk-27-1.png){width=672}\n:::\n:::\n\n\nPara valores altos de seguidores es menos probable que la cuenta sea falsa.\n\n#### Modelo con follows como variable independiente:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodelo16 <- lm(fake ~ follows, \n              data = datos)\n\nsummary(modelo16)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = fake ~ follows, data = datos)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-0.5623 -0.5094  0.3973  0.4462  1.3290 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  5.623e-01  2.325e-02  24.185  < 2e-16 ***\nfollows     -1.226e-04  2.217e-05  -5.528 4.92e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.488 on 574 degrees of freedom\nMultiple R-squared:  0.05055,\tAdjusted R-squared:  0.0489 \nF-statistic: 30.56 on 1 and 574 DF,  p-value: 4.916e-08\n```\n:::\n:::\n\n\nVeamos la predicción:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndatos %>%\n  ggplot(aes(x=follows, y=fake)) + \n  geom_point() + \n  geom_line(aes(x=follows, y=predict(modelo16),\n                color=\"red\"))\n```\n\n::: {.cell-output-display}\n![](regresion_files/figure-html/unnamed-chunk-29-1.png){width=672}\n:::\n:::\n\n\nPara valores altos de cuentas seguidas es menos probable que la cuenta sea falsa.\n\nComo hemos podido observar, las conclusiones extraídas coinciden con las conclusiones que hemos estado viendo en los apartados anteriores. La regresión es un mecanismo muy útil y sencillo para predecir valores esperados, tal y como hemos comprobado.\n\n### Predicción\n\nAhora, es momento de predecir la variable dependiente del dataset de test con el mejor modelo encontrado: modelo6.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Realizar la predicción con el modelo de regresión modelo6\nprediccion <- predict(modelo6, newdata = datos_test)\nprediccion\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n        1         2         3         4         5         6         7         8 \n0.5000205 0.1837676 0.1837676 0.1837676 0.6629387 0.1837676 0.1837676 0.1837676 \n        9        10        11        12        13        14        15        16 \n0.1837676 0.1837676 0.1837676 0.3179355 0.3179355 0.5000205 0.2796018 0.1837676 \n       17        18        19        20        21        22        23        24 \n0.5000205 0.1837676 0.1837676 0.1837676 0.6629387 0.1837676 0.3946029 0.1837676 \n       25        26        27        28        29        30        31        32 \n0.2796018 0.1837676 0.1837676 0.1837676 0.5000205 0.1837676 0.1837676 0.1837676 \n       33        34        35        36        37        38        39        40 \n0.1837676 0.1837676 0.3466857 0.1837676 0.1837676 0.1837676 0.1837676 0.3275189 \n       41        42        43        44        45        46        47        48 \n0.1837676 0.1837676 0.1837676 0.2700184 0.1837676 0.1837676 0.1837676 0.1837676 \n       49        50        51        52        53        54        55        56 \n0.1837676 0.1837676 0.1837676 0.1837676 0.1837676 0.1837676 0.1837676 0.1837676 \n       57        58        59        60        61        62        63        64 \n0.1837676 0.3179355 0.1837676 0.1837676 0.7648889 0.4425200 0.7840558 0.7169718 \n       65        66        67        68        69        70        71        72 \n0.7169718 0.9278071 0.7169718 0.7169718 0.7169718 1.3111440 0.7169718 1.1194755 \n       73        74        75        76        77        78        79        80 \n1.3111440 1.1961429 1.0140579 0.9757242 1.1961429 1.4357285 0.5958547 0.9565574 \n       81        82        83        84        85        86        87        88 \n1.0271087 1.0366922 0.1837676 0.4425200 0.7169718 0.7204392 0.1837676 0.8511397 \n       89        90        91        92        93        94        95        96 \n0.1837676 1.1961429 0.1837676 0.6629387 1.0332247 0.1837676 0.1837676 0.5479376 \n       97        98        99       100       101       102       103       104 \n0.7169718 0.5000205 1.0140579 0.8258569 0.5479376 0.5479376 0.7169718 0.6437718 \n      105       106       107       108       109       110       111       112 \n0.7300226 1.0271087 1.0366922 1.1386424 0.7169718 0.6054381 0.1837676 0.1837676 \n      113       114       115       116       117       118       119       120 \n1.1386424 0.6150216 0.5000205 0.4616868 0.5671045 0.1837676 0.8798900 0.6054381 \n```\n:::\n:::\n\n\nComo vemos, hay valores que se salen de los límites de \\[0,1\\], con lo que ajustaremos los valores predichos: \\< 0.5 será 0 y \\>= 0.5 será 1.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Ajustar los valores predichos: < 0.5 será 0 y >= 0.5 será 1\nfake_predict_regresion <- ifelse(prediccion < 0.5, 0, 1)\n\n# Leer el archivo CSV\ndatos_test_predicciones <- read.csv(\"datos_test_predicciones.csv\")\n\n# Guardar los valores ajustados en una nueva columna de datos_test_predicciones\ndatos_test_predicciones$fake_predict_regresion <- fake_predict_regresion\n\n# Mostrar las primera filas de datos_test_predicciones\nhead(datos_test_predicciones)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  fake fake_predict_RA fake_predict_FCA fake_predict_regresion\n1    0               1                1                      1\n2    0               0                0                      0\n3    0               0                0                      0\n4    0               0                0                      0\n5    0               1                0                      1\n6    0               1                0                      0\n```\n:::\n:::\n\n\nAhora, contemos el número de valores NA en la columna fake_predict_regresion:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Contar el número de valores NA en la columna fake_predict_regresion\ncat(\"La columna fake_predict_regresion tiene \", sum(is.na(datos_test_predicciones$fake_predict_regresion)), \" valores NA\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLa columna fake_predict_regresion tiene  0  valores NA\n```\n:::\n:::\n\n\nParece que la predicción ha sido satisfactoria. Ahora, calculemos el porcentaje de éxito en la predicción de cuentas falsas, de cuentas verdaderas y en general:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calcular el porcentaje de éxito en la predicción de cuentas falsas\npredicciones_correctas_falsas_regresion <- sum(datos_test_predicciones$fake_predict_regresion == datos_test_predicciones$fake & datos_test_predicciones$fake == 1)\ntotal_falsas_regresion <- sum(datos_test_predicciones$fake == 1)\nporcentaje_exito_falsas_regresion <- (predicciones_correctas_falsas_regresion / total_falsas_regresion) * 100\n\n# Calcular el porcentaje de éxito en la predicción de cuentas verdaderas\npredicciones_correctas_verdaderas_regresion <- sum(datos_test_predicciones$fake_predict_regresion == datos_test_predicciones$fake & datos_test_predicciones$fake == 0)\ntotal_verdaderas_regresion <- sum(datos_test_predicciones$fake == 0)\nporcentaje_exito_verdaderas_regresion <- (predicciones_correctas_verdaderas_regresion / total_verdaderas_regresion) * 100\n\n# Calcular el porcentaje de éxito general\npredicciones_correctas_regresion <- sum(datos_test_predicciones$fake_predict_regresion == datos_test_predicciones$fake)\ntotal_predicciones_regresion <- nrow(datos_test_predicciones)\nporcentaje_exito_general_regresion <- (predicciones_correctas_regresion / total_predicciones_regresion) * 100\n\n# Guardar el data frame en un archivo CSV\nwrite.csv(datos_test_predicciones, \"datos_test_predicciones.csv\", row.names = FALSE)\n\n# Imprimir el resultado\ncat(\"El porcentaje de éxito en la predicción de cuentas falsas es:\", porcentaje_exito_falsas_regresion, \"%\\n\", \"El porcentaje de éxito en la predicción de cuentas verdaderas es:\", porcentaje_exito_verdaderas_regresion, \"%\\n\", \"El porcentaje de éxito general en la predicción de cuentas es:\", porcentaje_exito_general_regresion, \"%\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nEl porcentaje de éxito en la predicción de cuentas falsas es: 80 %\n El porcentaje de éxito en la predicción de cuentas verdaderas es: 90 %\n El porcentaje de éxito general en la predicción de cuentas es: 85 %\n```\n:::\n:::\n\n\nComo vemos, los porcentajes de éxito son altos, lo que indica que el modelo de regresión ha sido efectivo en la predicción de cuentas falsas y verdaderas.\n\nAñadamos los porcentajes de éxito a la tabla de porcentajes:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Leer el archivo CSV\nexito_predicciones <- read.csv(\"exito_predicciones.csv\")\n\n# Añadir los porcentajes de éxito a la tabla de porcentajes\nexito_predicciones <- rbind(exito_predicciones, c(\"Regresión\", porcentaje_exito_falsas_regresion, porcentaje_exito_verdaderas_regresion, porcentaje_exito_general_regresion))\nexito_predicciones\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                  tipo Éxito_cuentas_falsas Éxito_cuentas_verdaderas\n1 Reglas de Asociación     83.3333333333333                       75\n2                  FCA                   80                       95\n3            Regresión                   80                       90\n     Éxito_general\n1 79.1666666666667\n2             87.5\n3               85\n```\n:::\n\n```{.r .cell-code}\n# Guardar el data frame en un archivo CSV\nwrite.csv(exito_predicciones, \"exito_predicciones.csv\", row.names = FALSE)\n```\n:::\n\n\nLas reglas de asociación han rendido algo mejor que la regresión en la predicción de cuentas falsas, pero la regresión ha sido mejor que las reglas de asociación en la predicción de cuentas verdaderas y en general. En general, la regresión ha sido 6 puntos más efectiva en la predicción general, con respecto a las reglas de asociación.\n\nFCA y regresión han rendido igual de bien en la predicción de cuentas falsas, pero FCA ha sido mejor en la predicción de cuentas verdaderas y en general. En general, FCA ha sido 2,5 puntos más efectiva en la predicción general, con respecto a la regresión.\n\n",
    "supporting": [
      "regresion_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}