{"title":"Reglas de Asociación","markdown":{"yaml":{"title":"Reglas de Asociación"},"headingText":"Librerías, datasets y procesamiento previo","containsRefs":false,"markdown":"\n\n```{r warning=FALSE, message=FALSE}\nlibrary(readr)\nlibrary(dplyr)\nlibrary(fcaR)\nlibrary(magrittr)\nlibrary(ggplot2)\nlibrary(psych)\nlibrary(arules)\n\ndatos <- read_csv(\"train.csv\")\nView(datos)\ndatos_test <- read_csv(\"test.csv\")\nView(datos_test)\n\ndatos <- rename(datos, profile_pic=`profile pic`, `nums/length_username` = `nums/length username`, fullname_words=`fullname words`, `nums/length_fullname` = `nums/length fullname`, description_length=`description length`, external_URL=`external URL`, posts=`#posts`, followers=`#followers`, follows=`#follows`)\n\ndatos_test <- rename(datos_test, profile_pic=`profile pic`, `nums/length_username` = `nums/length username`, fullname_words=`fullname words`, `nums/length_fullname` = `nums/length fullname`, description_length=`description length`, external_URL=`external URL`, posts=`#posts`, followers=`#followers`, follows=`#follows`)\n```\n\n## Reglas de Asociación\n\nYa hemos explorado, numérica y visualmente, el conjunto de datos de entrenamiento. A continuación, es turno de trabajar con las reglas de asociación, o lo que es lo mismo, descubrir relaciones y patrones de comportamiento revelados por los datos.\n\n### Obtención de las reglas\n\n```{r}\n# Eliminar las columnas de visualización\ndatos$num_length_interval <- NULL\ndatos$fullname_length_interval <- NULL\ndatos$description_length_interval <- NULL\ndatos$posts_interval <- NULL\ndatos$followers_interval <- NULL\ndatos$follows_interval <- NULL\n\nView(datos)\n```\n\nTras eliminar las columnas del apartado de visualización, pasemos a la generación de reglas de asociación, no sin antes ajustar el dataset para adecuarlo a la producción de las reglas.\n\nEn primer lugar, convertiremos el dataset a un data frame, y ajustaremos los tipos de las columnas. Necesitamos convertir las variables binarias al tipo \"factor\", para que no aparezcan intervalos del tipo \\[0,1\\] en estas variables en las reglas, así como discretizar a nuestro gusto las variables numéricas, para establecer categorías/intervalos razonables de acuerdo al dato particular con el que estemos trabajando:\n\n```{r}\n# Convertir dataset a data frame\ndatosDF <- data.frame(datos)\n\n# Mostrar tipo y un valor de las columnas 1 y 3\ncat(\"La clase de la columna 1 (profile_pic) es:\", class(datosDF[[1]]), \"\\nLa clase de la columna 3 (fullname_words) es:\", class(datosDF[[3]]))\n```\n\n```{r}\nhead(datosDF, 5)\n```\n\nComo vemos, los tipos iniciales de las variables profile_pic y fullname_words son numéricos.\n\nAhora pasemos a ajustar los tipos de datos:\n\n```{r}\n# Discretizar columnas numéricas\ndatosDF$nums.length_username <- discretize(datosDF$nums.length_username, method=\"interval\", breaks = 5)\ndatosDF$fullname_words <- discretize(datosDF$fullname_words, method=\"frequency\", breaks = 5)\ndatosDF$nums.length_fullname <- discretize(datosDF$nums.length_fullname, method=\"interval\", breaks = 5)\ndatosDF$description_length <- discretize(datosDF$description_length, method=\"frequency\", breaks = 5)\ndatosDF$posts <- discretize(datosDF$posts, method=\"frequency\", breaks = 7)\ndatosDF$followers <- discretize(datosDF$followers, method=\"frequency\", breaks = 10)\ndatosDF$follows <- discretize(datosDF$follows, method=\"frequency\", breaks = 7)\n\n# Identificar las columnas binarias y numéricas\ncolumnas_binarias <- c(1, 5, 7, 8, 12) # Índices de las columnas binarias\n\n# Convertir columnas binarias a factores\ndatosDF[, columnas_binarias] <- lapply(datosDF[, columnas_binarias], factor)\nView(datosDF)\n```\n\nExpliquemos el sentido de los parámetros usados en la discretización/conversión para cada variable:\n\n-   profile_pic: esta variable es binaria, con lo que se convierte a factor y tendrá 2 niveles.\n\n-   nums/length_username: esta variable es numérica pero está comprendida entre 0 y 1. Por ello, he usado 5 breaks (máximo de 5 categorías) y el método interval (categorías de igual tamaño).\n\n-   fullname_words: esta variable es numérica, con valores pequeños. Por ello, he usado 5 breaks (máximo de 5 categorías) y el método frequency (categorías de distinto tamaño, calculado en base a la frecuencia de los valores).\n\n-   nums/length_fullname: esta variable es numérica pero está comprendida entre 0 y 1. Por ello, he usado 5 breaks (máximo de 5 categorías) y el método interval (categorías de igual tamaño).\n\n-   name==username: esta variable es binaria, con lo que se convierte a factor y tendrá 2 niveles.\n\n-   description_length: esta variable es numérica, con valores relativamente pequeños. Por ello, he usado 5 breaks (máximo de 5 categorías) y el método frequency (categorías de distinto tamaño, calculado en base a la frecuencia de los valores).\n\n-   external_URL: esta variable es binaria, con lo que se convierte a factor y tendrá 2 niveles.\n\n-   private: esta variable es binaria, con lo que se convierte a factor y tendrá 2 niveles.\n\n-   posts: esta variable es numérica, con valores que pueden llegar a ser grandes. Por ello, he usado 7 breaks (máximo de 7 categorías) y el método frequency (categorías de distinto tamaño, calculado en base a la frecuencia de los valores).\n\n-   followers: esta variable es numérica, con valores que pueden llegar a ser enormes Por ello, he usado 10 breaks (máximo de 10 categorías) y el método frequency (categorías de distinto tamaño, calculado en base a la frecuencia de los valores).\n\n-   follows: esta variable es numérica, con valores que pueden llegar a ser grandes. Por ello, he usado 7 breaks (máximo de 7 categorías) y el método frequency (categorías de distinto tamaño, calculado en base a la frecuencia de los valores).\n\n-   fake: esta variable es binaria, con lo que se convierte a factor y tendrá 2 niveles.\n\nDiscretizar variables numéricas antes de crear reglas de asociación es recomendable, ya que ayuda a simplificar el análisis y mejorar la capacidad para manejar el ruido y la variabilidad en los datos.\n\nAhora, veamos los niveles (número de intervalos) que posee cada variable:\n\n```{r}\n# Obtener los niveles de cada variable recorriendo las columnas\nfor (col_name in names(datosDF)) {\n  col <- datosDF[[col_name]]\n  if (is.factor(col)) {\n    cat(length(levels(col)), \" niveles en\", col_name, \":\", levels(col), \"\\n\")\n  }\n}\n\n```\n\nAhora, veamos el cambio en el tipo de datos:\n\n```{r}\n# Mostrar tipo y un valor de las columnas 1 y 3\ncat(\"La clase de la columna 1 (profile_pic) es:\", class(datosDF[[1]]), \"\\nLa clase de la columna 3 (fullname_words) es:\", class(datosDF[[3]]))\n```\n\n```{r}\nhead(datosDF, 5)\n```\n\nComo podemos ver, ahora profile_pic tiene un valor 1 (de tipo factror), y fullname_words tiene valores comprendidos en un intervalo (categorías).\n\nPara generar reglas de asociación, se recomienda trabajar con datos de tipo transacción, ya que este tipo permite representar los datos en un formato adecuado para el algoritmo, facilitando la identificación de patrones de asociación. Por ello, convertiremos datosDF en tipo transacciones:\n\n```{r}\n# Convertir a tipo transacción\nTdatos <- as(datosDF, \"transactions\")\nclass(Tdatos)\n```\n\nUna vez preparados los datos, es hora de utilizar el algoritmo apriori para generar las reglas de asociación.\n\nPara generar las reglas, usaré un soporte de 0,1 (para que las reglas generadas tengan un mínimo razonable de apariciones en los datos) y una confianza del 90% (para extraer únicamente reglas precisas):\n\n```{r}\n# Generar reglas de asociación con suporte = 0,1 y confianza = 0,9\nreglas <- apriori(Tdatos, list(supp=0.1, conf=0.9))\n```\n\nVeamos cuántas reglas hay con soporte = 0,1 y confianza = 0,9:\n\n```{r}\n# Número de reglas con soporte = 0,1 y confianza = 0,9\nlength(reglas)\n```\n\nUn paso necesario al generar reglas es eliminar las redundantes:\n\n```{r}\n# Eliminar reglas redundantes\nindices_no_redundantes <- which(!is.redundant(reglas))\nreglas <- reglas[indices_no_redundantes]\n```\n\nVeamos cuántas reglas sin redundancia hay:\n\n```{r}\n# Número de reglas sin redundancia\nlength(reglas)\n```\n\nAhora, quedémonos únicamente con las reglas estadísticamente significativas:\n\n```{r}\nindices_significativos <- which(is.significant(reglas))\nreglas <- reglas[indices_significativos]\n```\n\nVeamos cuántas reglas significativas hay:\n\n```{r}\n# Número de reglas significativas\nlength(reglas)\n```\n\nUn parámetro muy importante para las reglas de asociación es el lift, ya que, si este dato es superior a 1, significa que el antecedente y el consecuente tienden a ocurrir juntos más frecuentemente de lo que se esperaría por azar. Es decir, un lift de 3 significa que el antecedente hace que el consecuente sea 3 veces más probable que ocurra.\n\nTambién nos interesa el count, es decir, el número de casos en los que esa regla se cumple. Ya hemos aplicado el filtro de soporte al crear las reglas, pero, por si acaso, establezcamos también un count mínimo de 50.\n\nApliquemos ambos filtros:\n\n```{r}\nreglas <- subset(reglas, subset = lift > 1 & count > 50)\n```\n\nVeamos cuántas reglas con lift \\> 1 y count \\> 50 hay:\n\n```{r}\n# Número de reglas con lift > 1 y count > 50\nlength(reglas)\n```\n\nEl número de reglas no ha disminuido, lo que sugiere que los filtros anteriores se han encargado de desechar las reglas con lift \\<= 1 y count \\<= 50.\n\nEchemos un vistazo a las primeras 15 reglas, ordenadas por confianza:\n\n```{r}\n# Visualizar las 20 primeras reglas\nreglas <- sort(reglas, by=\"confidence\")\ninspect(reglas[1:20])\n```\n\nComo vemos, las 20 reglas tienen 100% de confianza, y gracias a los filtros, tienen también buenos valores de lift y coverage.\n\nVeamos cuántas reglas tienen un 100% de confianza:\n\n```{r}\nreglas_confianza <- subset(reglas, confidence == 1)\nlength(reglas_confianza)\n```\n\nHay 55 reglas que son perfectamente precisas, es decir, que si aparece el antecedente, el consecuente también se cumple en el 100% de los casos.\n\nUna vez examinadas algunas características generales de las reglas, es el momento de quedarnos con las reglas realmente importantes para este proyecto, es decir, las que involucran al parámetro \"fake\". Nuestro objetivo actual es, pues, determinar qué parámetros son determinantes para decidir si una cuenta es falsa o verdadera (parámetro \"fake\" en el consecuente), así como analizar qué patrones suelen cumplirse en las cuentas falsas o verdaderas (parámetro \"fake\" en el antecedente).\n\nComencemos con el primer enfoque:\n\n### ¿Qué parámetros deciden si una cuenta es verdadera o falsa?\n\nPara encontrar las variables o conjuntos de variables que, en nuestro dataset, determinan si una cuenta es verdadera o falsa con total o casi total seguridad, es necesario encontrar las reglas que presenten el parámetro fake en su consecuente.\n\nPara cuentas falsas:\n\n```{r}\nreglas_fake <- subset(reglas, subset = rhs %in% \"fake=1\")\nlength(reglas_fake)\n```\n\n```{r}\ninspect(reglas_fake)\n```\n\nY para cuentas verdaderas:\n\n```{r}\nreglas_verdaderas <- subset(reglas, subset = rhs %in% \"fake=0\")\nlength(reglas_verdaderas)\n```\n\n```{r}\ninspect(reglas_verdaderas)\n```\n\nComo podemos observar, han quedado 21 reglas con fake=1 en el consecuente (cuentas falsas), y 29 reglas con fake=0 en el consecuente (cuentas verdaderas). Para analizar algunas reglas interesantes, primero combinemos ambos conjuntos de reglas:\n\n```{r}\n# Combinar ambas selecciones\nreglas_fake_verdaderas <- c(reglas_fake, reglas_verdaderas)\nlength(reglas_fake_verdaderas)\n```\n\nPor la longitud, sabemos que la combinación de las reglas ha sido exitosa. Ahora sí, analicemos las reglas.\n\nEn primer lugar, veamos si existen reglas con una sola variable en el antecedente:\n\n```{r}\nreglas_fv_1left <- subset(reglas_fake_verdaderas, size(lhs) == 1)\nlength(reglas_fv_1left)\n```\n\n```{r}\nreglas_fv_1left <- sort(reglas_fv_1left, by=\"confidence\")\ninspect(reglas_fv_1left)\n```\n\nComentemos las reglas obtenidas:\n\n1.  Como vemos, sólo una de estas reglas posee plena confianza, y, de hecho, la conocíamos con anterioridad: ya dijimos que, en este dataset, no había cuentas falsas con URL externa. Por lo tanto, si una cuenta tiene URL externa, será verdadera.\n\n2.  También mencionamos que la ausencia de foto de perfil llevaba a pensar en una cuenta falsa. Ahora lo podemos afirmar con una confianza del 98,83%.\n\n3.  Otra conclusión ya vista es la de que un número alto de publicaciones normalmente conduce a una cuenta verdadera. La confianza cuando el valor de publicaciones está entre 188 y 7390 (es el intervalo más alto) es del 98,79%.\n\n4.  Al igual que con la foto de perfil, la ausencia de publicaciones llevaba a pensar en cuentas falsas. En este caso, el intervalo es de 0-1 publicaciones, y nos garantiza falsedad de la cuenta en el 97,45% de los casos.\n\n5.  Esta regla es algo más extraña. El intervalo intermedio de valores del ratio de números en la longitud del username indica que la cuenta es falsa con confianza del 95%. Ya vimos, en la visualización, que los valores altos de esta variable aparecían en las cuentas falsas, con lo que probablemente los intervalos superiores aparecerán en los conjuntos de reglas con más de una variable en el antecedente.\n\nA continuación veremos todas estas reglas, y comentaremos las más llamativas:\n\n```{r}\nreglas_fake_verdaderas <- sort(reglas_fake_verdaderas, by=\"confidence\")\ninspect(reglas_fake_verdaderas)\n```\n\nPara extraer las conclusiones generales de estas 50 reglas, analicemos la frecuencia de aparición de los antecedentes, empezando con las cuentas falsas:\n\n```{r}\n# Seleccionar reglas donde rhs es \"fake=1\"\nreglas_fake_rhs <- subset(reglas, subset = rhs %in% \"fake=1\")\n\n# Convertir los antecedentes a una lista\nantecedentes_lista_f <- as(lhs(reglas_fake_rhs), \"list\")\n\n# Crear una tabla de frecuencias\nfrecuencia_ant_f <- table(unlist(antecedentes_lista_f))\n\n# Ordenar la tabla de frecuencias de forma descendente\nfrecuencia_ant_f_ordenada <- sort(frecuencia_ant_f, decreasing = TRUE)\n\nfrecuencia_ant_f_ordenada\n```\n\nPodemos afirmar con una seguridad considerable que una cuenta es falsa cuando identificamos ciertas combinaciones de estas características:\n\n-   Pocas palabras en el nombre completo\n-   Pocas o nulas publicaciones\n-   Descripción vacía o muy breve\n-   Ausencia de foto de perfil\n-   Ratio de números en la longitud del username entre 0,184 y 0,552\n-   Pocos o nulos seguidos\n-   Cuenta pública\n-   Ausencia de URL externa\n\nAhora veamos la frecuencia de aparición de los antecedentes para cuentas verdaderas:\n\n```{r}\n# Seleccionar reglas donde rhs es \"fake=0\"\nreglas_verdaderas_rhs <- subset(reglas, subset = rhs %in% \"fake=0\")\n\n# Convertir los antecedentes a una lista\nantecedentes_lista_v <- as(lhs(reglas_verdaderas_rhs), \"list\")\n\n# Crear una tabla de frecuencias\nfrecuencia_ant_v <- table(unlist(antecedentes_lista_v))\n\n# Ordenar la tabla de frecuencias de forma descendente\nfrecuencia_ant_v_ordenada <- sort(frecuencia_ant_v, decreasing = TRUE)\n\nfrecuencia_ant_v_ordenada\n```\n\nPodemos afirmar con una seguridad considerable que una cuenta es verdadera cuando identificamos ciertas combinaciones de estas características:\n\n-   Ratio de números en la longitud del username entre 0 y 0,184\n-   Cantidad considerable de palabras en el nombre completo\n-   Presencia de foto de perfil\n-   Descripción detallada\n-   Ratio de números en la longitud del nombre completo entre 0 y 0,2\n-   Cuenta privada \\*\n-   Número alto de publicaciones\n-   Cuenta pública \\*\n-   Número alto de seguidos\n-   Ausencia de coincidencia entre nombre completo y nombre de usuario\n-   Presencia de URL externa\n\nSorprende la ausencia en los antecedentes del número alto de seguidores.\n\n-   \\* Nota: es un ejemplo de variable que por sí sola no decide nada, pero que combinada con otras puede dar lugar a una conclusión o a otra. Recomiendo fijarse en la variable private en las siguientes reglas:\n\n```{r}\ninspect(c(reglas_fake_verdaderas[5], reglas_fake_verdaderas[10], reglas_fake_verdaderas[18]))\n```\n\n### Predicción\n\nUna vez llegados aquí, habiendo analizado las reglas de asociación del dataset de entrenamiento, es momento de probar la calidad de las reglas con el dataset de test.\n\nDebemos comenzar discretizando los valores del dataset de test con los mismos intervalos que usamos en el dataset de entrenamiento, ya que las reglas que vamos a usar poseen estos intervalos:\n\n```{r}\n# Convertir dataset de test a data frame\ndatos_testDF <- data.frame(datos_test)\n\nView(datos_test)\n\n# Guardar la columna fake en una variable aparte, para poder compararla al final con la predicción\nfake_originales <- datos_testDF$fake\n\n# Eliminar la columna fake\ndatos_testDF$fake <- NULL\n\nView(datos_testDF)\n\n# Discretizar columnas numéricas con los mismos intervalos que en el dataset de entrenamiento\n\n# Iterar sobre cada fila de datos_testDF\nfor (i in 1:nrow(datos_testDF)) {\n  # Para nums.length_username\n  if (datos_testDF[i, \"nums.length_username\"] < 0.184) {\n    datos_testDF[i, \"nums.length_username\"] <- \"[0,0.184)\"\n  } else if (datos_testDF[i, \"nums.length_username\"] < 0.368) {\n    datos_testDF[i, \"nums.length_username\"] <- \"[0.184,0.368)\"\n  } else if (datos_testDF[i, \"nums.length_username\"] < 0.552) {\n    datos_testDF[i, \"nums.length_username\"] <- \"[0.368,0.552)\"\n  } else if (datos_testDF[i, \"nums.length_username\"] < 0.736) {\n    datos_testDF[i, \"nums.length_username\"] <- \"[0.552,0.736)\"\n  } else {\n    datos_testDF[i, \"nums.length_username\"] <- \"[0.736,0.92]\"\n  }\n\n  # Para fullname_words\n  if (datos_testDF[i, \"fullname_words\"] < 1) {\n    datos_testDF[i, \"fullname_words\"] <- \"[0,1)\"\n  } else if (datos_testDF[i, \"fullname_words\"] < 2) {\n    datos_testDF[i, \"fullname_words\"] <- \"[1,2)\"\n  } else {\n    datos_testDF[i, \"fullname_words\"] <- \"[2,12]\"\n  }\n  \n  # Para nums.length_fullname\n  if (datos_testDF[i, \"nums.length_fullname\"] < 0.2) {\n    datos_testDF[i, \"nums.length_fullname\"] <- \"[0,0.2)\"\n  } else if (datos_testDF[i, \"nums.length_fullname\"] < 0.4) {\n    datos_testDF[i, \"nums.length_fullname\"] <- \"[0.2,0.4)\"\n  } else if (datos_testDF[i, \"nums.length_fullname\"] < 0.6) {\n    datos_testDF[i, \"nums.length_fullname\"] <- \"[0.4,0.6)\"\n  } else if (datos_testDF[i, \"nums.length_fullname\"] < 0.8) {\n    datos_testDF[i, \"nums.length_fullname\"] <- \"[0.6,0.8)\"\n  } else {\n    datos_testDF[i, \"nums.length_fullname\"] <- \"[0.8,1]\"\n  }\n  \n  # Para description_length\n  if (datos_testDF[i, \"description_length\"] < 5) {\n    datos_testDF[i, \"description_length\"] <- \"[0,5)\"\n  } else if (datos_testDF[i, \"description_length\"] < 43) {\n    datos_testDF[i, \"description_length\"] <- \"[5,43)\"\n  } else {\n    datos_testDF[i, \"description_length\"] <- \"[43,150]\"\n  }\n  \n  # Para posts\n  if (datos_testDF[i, \"posts\"] < 1) {\n    datos_testDF[i, \"posts\"] <- \"[0,1)\"\n  } else if (datos_testDF[i, \"posts\"] < 5) {\n    datos_testDF[i, \"posts\"] <- \"[1,5)\"\n  } else if (datos_testDF[i, \"posts\"] < 17.6) {\n    datos_testDF[i, \"posts\"] <- \"[5,17.6)\"\n  } else if (datos_testDF[i, \"posts\"] < 63.7) {\n    datos_testDF[i, \"posts\"] <- \"[17.6,63.7)\"\n  } else if (datos_testDF[i, \"posts\"] < 187) {\n    datos_testDF[i, \"posts\"] <- \"[63.7,187)\"\n  } else {\n    datos_testDF[i, \"posts\"] <- \"[187,7.39e+03]\"\n  }\n  \n  # Para followers\n  if (datos_testDF[i, \"followers\"] < 10.5) {\n    datos_testDF[i, \"followers\"] <- \"[0,10.5)\"\n  } else if (datos_testDF[i, \"followers\"] < 26) {\n    datos_testDF[i, \"followers\"] <- \"[10.5,26)\"\n  } else if (datos_testDF[i, \"followers\"] < 49) {\n    datos_testDF[i, \"followers\"] <- \"[26,49)\"\n  } else if (datos_testDF[i, \"followers\"] < 78) {\n    datos_testDF[i, \"followers\"] <- \"[49,78)\"\n  } else if (datos_testDF[i, \"followers\"] < 150) {\n    datos_testDF[i, \"followers\"] <- \"[78,150)\"\n  } else if (datos_testDF[i, \"followers\"] < 271) {\n    datos_testDF[i, \"followers\"] <- \"[150,271)\"\n  } else if (datos_testDF[i, \"followers\"] < 496) {\n    datos_testDF[i, \"followers\"] <- \"[271,496)\"\n  } else if (datos_testDF[i, \"followers\"] < 916) {\n    datos_testDF[i, \"followers\"] <- \"[496,916)\"\n  } else if (datos_testDF[i, \"followers\"] < 2580) {\n    datos_testDF[i, \"followers\"] <- \"[916,2.58e+03)\"\n  } else {\n    datos_testDF[i, \"followers\"] <- \"[2.58e+03,1.53e+07]\"\n  }\n  \n  # Para follows\n  if (datos_testDF[i, \"follows\"] < 26) {\n    datos_testDF[i, \"follows\"] <- \"[0,26)\"\n  } else if (datos_testDF[i, \"follows\"] < 71) {\n    datos_testDF[i, \"follows\"] <- \"[26,71)\"\n  } else if (datos_testDF[i, \"follows\"] < 159) {\n    datos_testDF[i, \"follows\"] <- \"[71,159)\"\n  } else if (datos_testDF[i, \"follows\"] < 322) {\n    datos_testDF[i, \"follows\"] <- \"[159,322)\"\n  } else if (datos_testDF[i, \"follows\"] < 521) {\n    datos_testDF[i, \"follows\"] <- \"[322,521)\"\n  } else if (datos_testDF[i, \"follows\"] < 904) {\n    datos_testDF[i, \"follows\"] <- \"[521,904)\"\n  } else {\n    datos_testDF[i, \"follows\"] <- \"[904,7.5e+03]\"\n  }\n  \n}\n\n# Concertir las columnas no binarias (las que ahora tienen intervalos) a tipo factor\ncolumnas_intervalo <- c(\"nums.length_username\", \"fullname_words\", \"nums.length_fullname\", \"description_length\", \"posts\", \"followers\", \"follows\")\ndatos_testDF[, columnas_intervalo] <- lapply(datos_testDF[, columnas_intervalo], factor)\n\n# Convertir columnas binarias a factor\ncolumnas_binarias <- c(1, 5, 7, 8)\ndatos_testDF[, columnas_binarias] <- lapply(datos_testDF[, columnas_binarias], factor)\n\n# Ver datos_testDF después de la conversión\nhead(datos_testDF)\n```\n\nComo vemos, todas las variables numéricas han pasado a tener datos de intervalo, y todas las columnas han pasado a ser de tipo factor.\n\nAhora toca aplicar las reglas a los datos de test, y realizar la predicción:\n\n```{r}\n# Convertir datos_test a transacciones\nTdatos_test <- as(datos_testDF, \"transactions\")\n\n# Crear una columna vacía para las predicciones\ndatos_testDF$fake_predict_RA <- NA\n\n# Aplicar las reglas a cada transacción en datos_test\nfor (i in 1:length(Tdatos_test)) {\n  # Obtener la transacción de esa fila\n  trans <- Tdatos_test[i]\n  \n  # Evaluar las reglas con el antecedente correspondiente: si el antecedente es subconjunto de la transacción actual, asignar el consecuente de la primera regla que lo cumpla (están ordenadas por confidence) a 'fake_predict_RA'\n  matches <- is.subset(lhs(reglas_fake_verdaderas), trans)\n  \n  # Si alguna regla se cumple, asignar el consecuente correspondiente a 'fake_predict_RA'\n  if (any(matches)) {\n    # Obtener el consecuente de la primera regla que se cumple\n    matching_rule <- reglas_fake_verdaderas[which(matches)[1]]\n    fake_value <- labels(rhs(matching_rule))[1]\n    \n    # Asignar el valor predicho\n    datos_testDF$fake_predict_RA[i] <- sub(\"fake=\", \"\", fake_value)\n  }\n  \n  # Si ninguna regla cuenta con un antecedente que sea subconjunto de la transacción actual, realizar una heurística (árbol de decisión) con las conclusiones extraídas de las reglas\n  else {\n    # Si la cuenta tiene URL externa, es verdadera\n    if (datos_test$external_URL[i] == 1) {\n      datos_testDF$fake_predict_RA[i] <- 0\n      # Si la cuenta no tiene foto de perfil, es falsa\n    } else if (datos_test$profile_pic[i] == 0) {\n      datos_testDF$fake_predict_RA[i] <- 1\n      # Si la cuenta tiene menos de 250 seguido, es falsa\n    } else if (datos_test$followers[i] < 250) {\n      datos_testDF$fake_predict_RA[i] <- 1\n      # En otro caso, consideramos que es verdadera\n    } else {\n      datos_testDF$fake_predict_RA[i] <- 0\n    }\n  }\n}\n```\n\nEchemos un vistazo a las primeras filas de datos_testDF para comprobar que la predicción se ha realizado correctamente:\n\n```{r}\n# Mostrar las primeras filas de datos_testDF\nhead(datos_testDF)\n\n#View(datos_testDF)\n```\n\nVemos que hay predicciones en la columna fake_predict_RA, aunque muchas de ellas (haciendo el View) contienen caracteres '{' y '}'. Deshagámonos de ellos y convirtamos la columna a numérica para poder compararla con la columna fake original:\n\n```{r}\n# Convertir datos_testDF$fake_predict_RA para eliminar los caracteres '{' y '}'\ndatos_testDF$fake_predict_RA <- gsub(\"\\\\{|\\\\}\", \"\", datos_testDF$fake_predict_RA)\n\n# Convertir datos_testDF$fake_predict_RA a numérico\ndatos_testDF$fake_predict_RA <- as.numeric(datos_testDF$fake_predict_RA)\n\n# Mostrar las primeras filas de datos_testDF\nhead(datos_testDF)\n```\n\nMisión cumplida. Ahora, revisemos si hay valores NA en esa columna:\n\n```{r}\n# Contar los valores NA de la columna fake_predict_RA\ncat(\"fake_predict_RA tiene \", sum(is.na(datos_testDF$fake_predict_RA)), \" valores NA.\")\n```\n\nParece que todo va bien. Creemos un nuevo dataset únicamente formado por las predicciones y el valor real de falsedad:\n\n```{r}\ndatos_test_predicciones <- data.frame(fake = fake_originales, fake_predict_RA = datos_testDF$fake_predict_RA)\nView(datos_test_predicciones)\n# Guardar el data frame en un archivo CSV\nwrite.csv(datos_test_predicciones, \"datos_test_predicciones.csv\", row.names = FALSE)\n```\n\nEs momento de calcular el porcentaje de éxito en la predicción de cuentas falsas, verdaderas y en general:\n\n```{r}\n# Contar el número de predicciones correctas cuando la cuenta es falsa\npredicciones_correctas_falsas <- sum(datos_test_predicciones$fake_predict_RA == datos_test_predicciones$fake & datos_test_predicciones$fake == 1)\n\n# Calcular el porcentaje de éxito en la predicción de cuentas falsas\ntotal_falsas <- sum(datos_test_predicciones$fake == 1)\nporcentaje_exito_falsas <- (predicciones_correctas_falsas / total_falsas) * 100\n\n# Contar el número de predicciones correctas cuando la cuenta es verdadera\npredicciones_correctas_verdaderas <- sum(datos_test_predicciones$fake_predict_RA == datos_test_predicciones$fake & datos_test_predicciones$fake == 0)\n\n# Calcular el porcentaje de éxito en la predicción de cuentas verdaderas\ntotal_verdaderas <- sum(datos_test_predicciones$fake == 0)\nporcentaje_exito_verdaderas <- (predicciones_correctas_verdaderas / total_verdaderas) * 100\n\n# Contar el número de predicciones correctas generales\npredicciones_correctas <- sum(datos_test_predicciones$fake_predict_RA == datos_test_predicciones$fake)\n\n# Calcular el porcentaje de éxito general\ntotal_predicciones <- nrow(datos_test_predicciones)\nporcentaje_exito_general <- (predicciones_correctas / total_predicciones) * 100\n\n# Imprimir el resultado\ncat(\"El porcentaje de éxito en la predicción de cuentas falsas es:\", porcentaje_exito_falsas, \"%\\n\", \"El porcentaje de éxito en la predicción de cuentas verdaderas es:\", porcentaje_exito_verdaderas, \"%\\n\", \"El porcentaje de éxito general en la predicción de cuentas es:\", porcentaje_exito_general, \"%\\n\")\n```\n\nComo vemos, los porcentajes de éxito de predicción de la veracidad de la cuenta basados en las reglas de asociación son altos. Podrían mejorarse (especialmente el porcentaje para cuentas verdaderas), pero es un resultado satisfactorio.\n\n```{r}\n# Crear dataset con los porcentajes\nexito_predicciones <- data.frame(tipo = c(\"Reglas de Asociación\"), 'Éxito_cuentas_falsas' = c(porcentaje_exito_falsas), 'Éxito_cuentas_verdaderas' = c(porcentaje_exito_verdaderas), 'Éxito_general' = c(porcentaje_exito_general))\nexito_predicciones\n\n# Guardar el data frame en un archivo CSV\nwrite.csv(exito_predicciones, \"exito_predicciones.csv\", row.names = FALSE)\n```\n\n### ¿Qué patrones encontramos conociendo la veracidad o falsedad de la cuenta?\n\nEn cuanto al objetivo del proyecto, nos importa más el apartado anterior (averiguar las causas que provocan que una cuenta sea verdadera o falsa para poder identificar cuentas falsas según sus parámetros), pero también resulta interesante, al menos, ver las reglas en sentido contrario, es decir, sabiendo que una cuenta es verdadera o falsa, ¿qué valores toman los demás atributos?\n\nNo me detendré a hacer un análisis profundo de este apartado, pero encontremos y observemos las reglas resultantes, comenzando con cuentas falsas:\n\n```{r}\nreglas_fake_lhs <- subset(reglas, subset = lhs %in% \"fake=1\")\nlength(reglas_fake_lhs)\n```\n\n```{r}\ninspect(reglas_fake_lhs)\n```\n\nDestaca la repetida aparición de valores bajos de longitud de la descripción en el consecuente, cuando se combina la falsedad de la cuenta con otros atributos en el antecedente. No extraemos mucha información nueva.\n\nVeamos estas reglas para cuentas verdaderas:\n\n```{r}\nreglas_verdaderas_lhs <- subset(reglas, subset = lhs %in% \"fake=0\")\nlength(reglas_verdaderas_lhs)\n```\n\n```{r}\ninspect(reglas_verdaderas_lhs)\n```\n\nDestaca la repetida aparición en los consecuentes de la presencia de foto de perfil, la ausencia de coincidencia de nombre completo y nombre de usuario y el primer intervalo de valores de los ratios de números en la longitud del username y del fullname.\n\n","srcMarkdownNoYaml":"\n\n```{r warning=FALSE, message=FALSE}\n# Librerías, datasets y procesamiento previo\nlibrary(readr)\nlibrary(dplyr)\nlibrary(fcaR)\nlibrary(magrittr)\nlibrary(ggplot2)\nlibrary(psych)\nlibrary(arules)\n\ndatos <- read_csv(\"train.csv\")\nView(datos)\ndatos_test <- read_csv(\"test.csv\")\nView(datos_test)\n\ndatos <- rename(datos, profile_pic=`profile pic`, `nums/length_username` = `nums/length username`, fullname_words=`fullname words`, `nums/length_fullname` = `nums/length fullname`, description_length=`description length`, external_URL=`external URL`, posts=`#posts`, followers=`#followers`, follows=`#follows`)\n\ndatos_test <- rename(datos_test, profile_pic=`profile pic`, `nums/length_username` = `nums/length username`, fullname_words=`fullname words`, `nums/length_fullname` = `nums/length fullname`, description_length=`description length`, external_URL=`external URL`, posts=`#posts`, followers=`#followers`, follows=`#follows`)\n```\n\n## Reglas de Asociación\n\nYa hemos explorado, numérica y visualmente, el conjunto de datos de entrenamiento. A continuación, es turno de trabajar con las reglas de asociación, o lo que es lo mismo, descubrir relaciones y patrones de comportamiento revelados por los datos.\n\n### Obtención de las reglas\n\n```{r}\n# Eliminar las columnas de visualización\ndatos$num_length_interval <- NULL\ndatos$fullname_length_interval <- NULL\ndatos$description_length_interval <- NULL\ndatos$posts_interval <- NULL\ndatos$followers_interval <- NULL\ndatos$follows_interval <- NULL\n\nView(datos)\n```\n\nTras eliminar las columnas del apartado de visualización, pasemos a la generación de reglas de asociación, no sin antes ajustar el dataset para adecuarlo a la producción de las reglas.\n\nEn primer lugar, convertiremos el dataset a un data frame, y ajustaremos los tipos de las columnas. Necesitamos convertir las variables binarias al tipo \"factor\", para que no aparezcan intervalos del tipo \\[0,1\\] en estas variables en las reglas, así como discretizar a nuestro gusto las variables numéricas, para establecer categorías/intervalos razonables de acuerdo al dato particular con el que estemos trabajando:\n\n```{r}\n# Convertir dataset a data frame\ndatosDF <- data.frame(datos)\n\n# Mostrar tipo y un valor de las columnas 1 y 3\ncat(\"La clase de la columna 1 (profile_pic) es:\", class(datosDF[[1]]), \"\\nLa clase de la columna 3 (fullname_words) es:\", class(datosDF[[3]]))\n```\n\n```{r}\nhead(datosDF, 5)\n```\n\nComo vemos, los tipos iniciales de las variables profile_pic y fullname_words son numéricos.\n\nAhora pasemos a ajustar los tipos de datos:\n\n```{r}\n# Discretizar columnas numéricas\ndatosDF$nums.length_username <- discretize(datosDF$nums.length_username, method=\"interval\", breaks = 5)\ndatosDF$fullname_words <- discretize(datosDF$fullname_words, method=\"frequency\", breaks = 5)\ndatosDF$nums.length_fullname <- discretize(datosDF$nums.length_fullname, method=\"interval\", breaks = 5)\ndatosDF$description_length <- discretize(datosDF$description_length, method=\"frequency\", breaks = 5)\ndatosDF$posts <- discretize(datosDF$posts, method=\"frequency\", breaks = 7)\ndatosDF$followers <- discretize(datosDF$followers, method=\"frequency\", breaks = 10)\ndatosDF$follows <- discretize(datosDF$follows, method=\"frequency\", breaks = 7)\n\n# Identificar las columnas binarias y numéricas\ncolumnas_binarias <- c(1, 5, 7, 8, 12) # Índices de las columnas binarias\n\n# Convertir columnas binarias a factores\ndatosDF[, columnas_binarias] <- lapply(datosDF[, columnas_binarias], factor)\nView(datosDF)\n```\n\nExpliquemos el sentido de los parámetros usados en la discretización/conversión para cada variable:\n\n-   profile_pic: esta variable es binaria, con lo que se convierte a factor y tendrá 2 niveles.\n\n-   nums/length_username: esta variable es numérica pero está comprendida entre 0 y 1. Por ello, he usado 5 breaks (máximo de 5 categorías) y el método interval (categorías de igual tamaño).\n\n-   fullname_words: esta variable es numérica, con valores pequeños. Por ello, he usado 5 breaks (máximo de 5 categorías) y el método frequency (categorías de distinto tamaño, calculado en base a la frecuencia de los valores).\n\n-   nums/length_fullname: esta variable es numérica pero está comprendida entre 0 y 1. Por ello, he usado 5 breaks (máximo de 5 categorías) y el método interval (categorías de igual tamaño).\n\n-   name==username: esta variable es binaria, con lo que se convierte a factor y tendrá 2 niveles.\n\n-   description_length: esta variable es numérica, con valores relativamente pequeños. Por ello, he usado 5 breaks (máximo de 5 categorías) y el método frequency (categorías de distinto tamaño, calculado en base a la frecuencia de los valores).\n\n-   external_URL: esta variable es binaria, con lo que se convierte a factor y tendrá 2 niveles.\n\n-   private: esta variable es binaria, con lo que se convierte a factor y tendrá 2 niveles.\n\n-   posts: esta variable es numérica, con valores que pueden llegar a ser grandes. Por ello, he usado 7 breaks (máximo de 7 categorías) y el método frequency (categorías de distinto tamaño, calculado en base a la frecuencia de los valores).\n\n-   followers: esta variable es numérica, con valores que pueden llegar a ser enormes Por ello, he usado 10 breaks (máximo de 10 categorías) y el método frequency (categorías de distinto tamaño, calculado en base a la frecuencia de los valores).\n\n-   follows: esta variable es numérica, con valores que pueden llegar a ser grandes. Por ello, he usado 7 breaks (máximo de 7 categorías) y el método frequency (categorías de distinto tamaño, calculado en base a la frecuencia de los valores).\n\n-   fake: esta variable es binaria, con lo que se convierte a factor y tendrá 2 niveles.\n\nDiscretizar variables numéricas antes de crear reglas de asociación es recomendable, ya que ayuda a simplificar el análisis y mejorar la capacidad para manejar el ruido y la variabilidad en los datos.\n\nAhora, veamos los niveles (número de intervalos) que posee cada variable:\n\n```{r}\n# Obtener los niveles de cada variable recorriendo las columnas\nfor (col_name in names(datosDF)) {\n  col <- datosDF[[col_name]]\n  if (is.factor(col)) {\n    cat(length(levels(col)), \" niveles en\", col_name, \":\", levels(col), \"\\n\")\n  }\n}\n\n```\n\nAhora, veamos el cambio en el tipo de datos:\n\n```{r}\n# Mostrar tipo y un valor de las columnas 1 y 3\ncat(\"La clase de la columna 1 (profile_pic) es:\", class(datosDF[[1]]), \"\\nLa clase de la columna 3 (fullname_words) es:\", class(datosDF[[3]]))\n```\n\n```{r}\nhead(datosDF, 5)\n```\n\nComo podemos ver, ahora profile_pic tiene un valor 1 (de tipo factror), y fullname_words tiene valores comprendidos en un intervalo (categorías).\n\nPara generar reglas de asociación, se recomienda trabajar con datos de tipo transacción, ya que este tipo permite representar los datos en un formato adecuado para el algoritmo, facilitando la identificación de patrones de asociación. Por ello, convertiremos datosDF en tipo transacciones:\n\n```{r}\n# Convertir a tipo transacción\nTdatos <- as(datosDF, \"transactions\")\nclass(Tdatos)\n```\n\nUna vez preparados los datos, es hora de utilizar el algoritmo apriori para generar las reglas de asociación.\n\nPara generar las reglas, usaré un soporte de 0,1 (para que las reglas generadas tengan un mínimo razonable de apariciones en los datos) y una confianza del 90% (para extraer únicamente reglas precisas):\n\n```{r}\n# Generar reglas de asociación con suporte = 0,1 y confianza = 0,9\nreglas <- apriori(Tdatos, list(supp=0.1, conf=0.9))\n```\n\nVeamos cuántas reglas hay con soporte = 0,1 y confianza = 0,9:\n\n```{r}\n# Número de reglas con soporte = 0,1 y confianza = 0,9\nlength(reglas)\n```\n\nUn paso necesario al generar reglas es eliminar las redundantes:\n\n```{r}\n# Eliminar reglas redundantes\nindices_no_redundantes <- which(!is.redundant(reglas))\nreglas <- reglas[indices_no_redundantes]\n```\n\nVeamos cuántas reglas sin redundancia hay:\n\n```{r}\n# Número de reglas sin redundancia\nlength(reglas)\n```\n\nAhora, quedémonos únicamente con las reglas estadísticamente significativas:\n\n```{r}\nindices_significativos <- which(is.significant(reglas))\nreglas <- reglas[indices_significativos]\n```\n\nVeamos cuántas reglas significativas hay:\n\n```{r}\n# Número de reglas significativas\nlength(reglas)\n```\n\nUn parámetro muy importante para las reglas de asociación es el lift, ya que, si este dato es superior a 1, significa que el antecedente y el consecuente tienden a ocurrir juntos más frecuentemente de lo que se esperaría por azar. Es decir, un lift de 3 significa que el antecedente hace que el consecuente sea 3 veces más probable que ocurra.\n\nTambién nos interesa el count, es decir, el número de casos en los que esa regla se cumple. Ya hemos aplicado el filtro de soporte al crear las reglas, pero, por si acaso, establezcamos también un count mínimo de 50.\n\nApliquemos ambos filtros:\n\n```{r}\nreglas <- subset(reglas, subset = lift > 1 & count > 50)\n```\n\nVeamos cuántas reglas con lift \\> 1 y count \\> 50 hay:\n\n```{r}\n# Número de reglas con lift > 1 y count > 50\nlength(reglas)\n```\n\nEl número de reglas no ha disminuido, lo que sugiere que los filtros anteriores se han encargado de desechar las reglas con lift \\<= 1 y count \\<= 50.\n\nEchemos un vistazo a las primeras 15 reglas, ordenadas por confianza:\n\n```{r}\n# Visualizar las 20 primeras reglas\nreglas <- sort(reglas, by=\"confidence\")\ninspect(reglas[1:20])\n```\n\nComo vemos, las 20 reglas tienen 100% de confianza, y gracias a los filtros, tienen también buenos valores de lift y coverage.\n\nVeamos cuántas reglas tienen un 100% de confianza:\n\n```{r}\nreglas_confianza <- subset(reglas, confidence == 1)\nlength(reglas_confianza)\n```\n\nHay 55 reglas que son perfectamente precisas, es decir, que si aparece el antecedente, el consecuente también se cumple en el 100% de los casos.\n\nUna vez examinadas algunas características generales de las reglas, es el momento de quedarnos con las reglas realmente importantes para este proyecto, es decir, las que involucran al parámetro \"fake\". Nuestro objetivo actual es, pues, determinar qué parámetros son determinantes para decidir si una cuenta es falsa o verdadera (parámetro \"fake\" en el consecuente), así como analizar qué patrones suelen cumplirse en las cuentas falsas o verdaderas (parámetro \"fake\" en el antecedente).\n\nComencemos con el primer enfoque:\n\n### ¿Qué parámetros deciden si una cuenta es verdadera o falsa?\n\nPara encontrar las variables o conjuntos de variables que, en nuestro dataset, determinan si una cuenta es verdadera o falsa con total o casi total seguridad, es necesario encontrar las reglas que presenten el parámetro fake en su consecuente.\n\nPara cuentas falsas:\n\n```{r}\nreglas_fake <- subset(reglas, subset = rhs %in% \"fake=1\")\nlength(reglas_fake)\n```\n\n```{r}\ninspect(reglas_fake)\n```\n\nY para cuentas verdaderas:\n\n```{r}\nreglas_verdaderas <- subset(reglas, subset = rhs %in% \"fake=0\")\nlength(reglas_verdaderas)\n```\n\n```{r}\ninspect(reglas_verdaderas)\n```\n\nComo podemos observar, han quedado 21 reglas con fake=1 en el consecuente (cuentas falsas), y 29 reglas con fake=0 en el consecuente (cuentas verdaderas). Para analizar algunas reglas interesantes, primero combinemos ambos conjuntos de reglas:\n\n```{r}\n# Combinar ambas selecciones\nreglas_fake_verdaderas <- c(reglas_fake, reglas_verdaderas)\nlength(reglas_fake_verdaderas)\n```\n\nPor la longitud, sabemos que la combinación de las reglas ha sido exitosa. Ahora sí, analicemos las reglas.\n\nEn primer lugar, veamos si existen reglas con una sola variable en el antecedente:\n\n```{r}\nreglas_fv_1left <- subset(reglas_fake_verdaderas, size(lhs) == 1)\nlength(reglas_fv_1left)\n```\n\n```{r}\nreglas_fv_1left <- sort(reglas_fv_1left, by=\"confidence\")\ninspect(reglas_fv_1left)\n```\n\nComentemos las reglas obtenidas:\n\n1.  Como vemos, sólo una de estas reglas posee plena confianza, y, de hecho, la conocíamos con anterioridad: ya dijimos que, en este dataset, no había cuentas falsas con URL externa. Por lo tanto, si una cuenta tiene URL externa, será verdadera.\n\n2.  También mencionamos que la ausencia de foto de perfil llevaba a pensar en una cuenta falsa. Ahora lo podemos afirmar con una confianza del 98,83%.\n\n3.  Otra conclusión ya vista es la de que un número alto de publicaciones normalmente conduce a una cuenta verdadera. La confianza cuando el valor de publicaciones está entre 188 y 7390 (es el intervalo más alto) es del 98,79%.\n\n4.  Al igual que con la foto de perfil, la ausencia de publicaciones llevaba a pensar en cuentas falsas. En este caso, el intervalo es de 0-1 publicaciones, y nos garantiza falsedad de la cuenta en el 97,45% de los casos.\n\n5.  Esta regla es algo más extraña. El intervalo intermedio de valores del ratio de números en la longitud del username indica que la cuenta es falsa con confianza del 95%. Ya vimos, en la visualización, que los valores altos de esta variable aparecían en las cuentas falsas, con lo que probablemente los intervalos superiores aparecerán en los conjuntos de reglas con más de una variable en el antecedente.\n\nA continuación veremos todas estas reglas, y comentaremos las más llamativas:\n\n```{r}\nreglas_fake_verdaderas <- sort(reglas_fake_verdaderas, by=\"confidence\")\ninspect(reglas_fake_verdaderas)\n```\n\nPara extraer las conclusiones generales de estas 50 reglas, analicemos la frecuencia de aparición de los antecedentes, empezando con las cuentas falsas:\n\n```{r}\n# Seleccionar reglas donde rhs es \"fake=1\"\nreglas_fake_rhs <- subset(reglas, subset = rhs %in% \"fake=1\")\n\n# Convertir los antecedentes a una lista\nantecedentes_lista_f <- as(lhs(reglas_fake_rhs), \"list\")\n\n# Crear una tabla de frecuencias\nfrecuencia_ant_f <- table(unlist(antecedentes_lista_f))\n\n# Ordenar la tabla de frecuencias de forma descendente\nfrecuencia_ant_f_ordenada <- sort(frecuencia_ant_f, decreasing = TRUE)\n\nfrecuencia_ant_f_ordenada\n```\n\nPodemos afirmar con una seguridad considerable que una cuenta es falsa cuando identificamos ciertas combinaciones de estas características:\n\n-   Pocas palabras en el nombre completo\n-   Pocas o nulas publicaciones\n-   Descripción vacía o muy breve\n-   Ausencia de foto de perfil\n-   Ratio de números en la longitud del username entre 0,184 y 0,552\n-   Pocos o nulos seguidos\n-   Cuenta pública\n-   Ausencia de URL externa\n\nAhora veamos la frecuencia de aparición de los antecedentes para cuentas verdaderas:\n\n```{r}\n# Seleccionar reglas donde rhs es \"fake=0\"\nreglas_verdaderas_rhs <- subset(reglas, subset = rhs %in% \"fake=0\")\n\n# Convertir los antecedentes a una lista\nantecedentes_lista_v <- as(lhs(reglas_verdaderas_rhs), \"list\")\n\n# Crear una tabla de frecuencias\nfrecuencia_ant_v <- table(unlist(antecedentes_lista_v))\n\n# Ordenar la tabla de frecuencias de forma descendente\nfrecuencia_ant_v_ordenada <- sort(frecuencia_ant_v, decreasing = TRUE)\n\nfrecuencia_ant_v_ordenada\n```\n\nPodemos afirmar con una seguridad considerable que una cuenta es verdadera cuando identificamos ciertas combinaciones de estas características:\n\n-   Ratio de números en la longitud del username entre 0 y 0,184\n-   Cantidad considerable de palabras en el nombre completo\n-   Presencia de foto de perfil\n-   Descripción detallada\n-   Ratio de números en la longitud del nombre completo entre 0 y 0,2\n-   Cuenta privada \\*\n-   Número alto de publicaciones\n-   Cuenta pública \\*\n-   Número alto de seguidos\n-   Ausencia de coincidencia entre nombre completo y nombre de usuario\n-   Presencia de URL externa\n\nSorprende la ausencia en los antecedentes del número alto de seguidores.\n\n-   \\* Nota: es un ejemplo de variable que por sí sola no decide nada, pero que combinada con otras puede dar lugar a una conclusión o a otra. Recomiendo fijarse en la variable private en las siguientes reglas:\n\n```{r}\ninspect(c(reglas_fake_verdaderas[5], reglas_fake_verdaderas[10], reglas_fake_verdaderas[18]))\n```\n\n### Predicción\n\nUna vez llegados aquí, habiendo analizado las reglas de asociación del dataset de entrenamiento, es momento de probar la calidad de las reglas con el dataset de test.\n\nDebemos comenzar discretizando los valores del dataset de test con los mismos intervalos que usamos en el dataset de entrenamiento, ya que las reglas que vamos a usar poseen estos intervalos:\n\n```{r}\n# Convertir dataset de test a data frame\ndatos_testDF <- data.frame(datos_test)\n\nView(datos_test)\n\n# Guardar la columna fake en una variable aparte, para poder compararla al final con la predicción\nfake_originales <- datos_testDF$fake\n\n# Eliminar la columna fake\ndatos_testDF$fake <- NULL\n\nView(datos_testDF)\n\n# Discretizar columnas numéricas con los mismos intervalos que en el dataset de entrenamiento\n\n# Iterar sobre cada fila de datos_testDF\nfor (i in 1:nrow(datos_testDF)) {\n  # Para nums.length_username\n  if (datos_testDF[i, \"nums.length_username\"] < 0.184) {\n    datos_testDF[i, \"nums.length_username\"] <- \"[0,0.184)\"\n  } else if (datos_testDF[i, \"nums.length_username\"] < 0.368) {\n    datos_testDF[i, \"nums.length_username\"] <- \"[0.184,0.368)\"\n  } else if (datos_testDF[i, \"nums.length_username\"] < 0.552) {\n    datos_testDF[i, \"nums.length_username\"] <- \"[0.368,0.552)\"\n  } else if (datos_testDF[i, \"nums.length_username\"] < 0.736) {\n    datos_testDF[i, \"nums.length_username\"] <- \"[0.552,0.736)\"\n  } else {\n    datos_testDF[i, \"nums.length_username\"] <- \"[0.736,0.92]\"\n  }\n\n  # Para fullname_words\n  if (datos_testDF[i, \"fullname_words\"] < 1) {\n    datos_testDF[i, \"fullname_words\"] <- \"[0,1)\"\n  } else if (datos_testDF[i, \"fullname_words\"] < 2) {\n    datos_testDF[i, \"fullname_words\"] <- \"[1,2)\"\n  } else {\n    datos_testDF[i, \"fullname_words\"] <- \"[2,12]\"\n  }\n  \n  # Para nums.length_fullname\n  if (datos_testDF[i, \"nums.length_fullname\"] < 0.2) {\n    datos_testDF[i, \"nums.length_fullname\"] <- \"[0,0.2)\"\n  } else if (datos_testDF[i, \"nums.length_fullname\"] < 0.4) {\n    datos_testDF[i, \"nums.length_fullname\"] <- \"[0.2,0.4)\"\n  } else if (datos_testDF[i, \"nums.length_fullname\"] < 0.6) {\n    datos_testDF[i, \"nums.length_fullname\"] <- \"[0.4,0.6)\"\n  } else if (datos_testDF[i, \"nums.length_fullname\"] < 0.8) {\n    datos_testDF[i, \"nums.length_fullname\"] <- \"[0.6,0.8)\"\n  } else {\n    datos_testDF[i, \"nums.length_fullname\"] <- \"[0.8,1]\"\n  }\n  \n  # Para description_length\n  if (datos_testDF[i, \"description_length\"] < 5) {\n    datos_testDF[i, \"description_length\"] <- \"[0,5)\"\n  } else if (datos_testDF[i, \"description_length\"] < 43) {\n    datos_testDF[i, \"description_length\"] <- \"[5,43)\"\n  } else {\n    datos_testDF[i, \"description_length\"] <- \"[43,150]\"\n  }\n  \n  # Para posts\n  if (datos_testDF[i, \"posts\"] < 1) {\n    datos_testDF[i, \"posts\"] <- \"[0,1)\"\n  } else if (datos_testDF[i, \"posts\"] < 5) {\n    datos_testDF[i, \"posts\"] <- \"[1,5)\"\n  } else if (datos_testDF[i, \"posts\"] < 17.6) {\n    datos_testDF[i, \"posts\"] <- \"[5,17.6)\"\n  } else if (datos_testDF[i, \"posts\"] < 63.7) {\n    datos_testDF[i, \"posts\"] <- \"[17.6,63.7)\"\n  } else if (datos_testDF[i, \"posts\"] < 187) {\n    datos_testDF[i, \"posts\"] <- \"[63.7,187)\"\n  } else {\n    datos_testDF[i, \"posts\"] <- \"[187,7.39e+03]\"\n  }\n  \n  # Para followers\n  if (datos_testDF[i, \"followers\"] < 10.5) {\n    datos_testDF[i, \"followers\"] <- \"[0,10.5)\"\n  } else if (datos_testDF[i, \"followers\"] < 26) {\n    datos_testDF[i, \"followers\"] <- \"[10.5,26)\"\n  } else if (datos_testDF[i, \"followers\"] < 49) {\n    datos_testDF[i, \"followers\"] <- \"[26,49)\"\n  } else if (datos_testDF[i, \"followers\"] < 78) {\n    datos_testDF[i, \"followers\"] <- \"[49,78)\"\n  } else if (datos_testDF[i, \"followers\"] < 150) {\n    datos_testDF[i, \"followers\"] <- \"[78,150)\"\n  } else if (datos_testDF[i, \"followers\"] < 271) {\n    datos_testDF[i, \"followers\"] <- \"[150,271)\"\n  } else if (datos_testDF[i, \"followers\"] < 496) {\n    datos_testDF[i, \"followers\"] <- \"[271,496)\"\n  } else if (datos_testDF[i, \"followers\"] < 916) {\n    datos_testDF[i, \"followers\"] <- \"[496,916)\"\n  } else if (datos_testDF[i, \"followers\"] < 2580) {\n    datos_testDF[i, \"followers\"] <- \"[916,2.58e+03)\"\n  } else {\n    datos_testDF[i, \"followers\"] <- \"[2.58e+03,1.53e+07]\"\n  }\n  \n  # Para follows\n  if (datos_testDF[i, \"follows\"] < 26) {\n    datos_testDF[i, \"follows\"] <- \"[0,26)\"\n  } else if (datos_testDF[i, \"follows\"] < 71) {\n    datos_testDF[i, \"follows\"] <- \"[26,71)\"\n  } else if (datos_testDF[i, \"follows\"] < 159) {\n    datos_testDF[i, \"follows\"] <- \"[71,159)\"\n  } else if (datos_testDF[i, \"follows\"] < 322) {\n    datos_testDF[i, \"follows\"] <- \"[159,322)\"\n  } else if (datos_testDF[i, \"follows\"] < 521) {\n    datos_testDF[i, \"follows\"] <- \"[322,521)\"\n  } else if (datos_testDF[i, \"follows\"] < 904) {\n    datos_testDF[i, \"follows\"] <- \"[521,904)\"\n  } else {\n    datos_testDF[i, \"follows\"] <- \"[904,7.5e+03]\"\n  }\n  \n}\n\n# Concertir las columnas no binarias (las que ahora tienen intervalos) a tipo factor\ncolumnas_intervalo <- c(\"nums.length_username\", \"fullname_words\", \"nums.length_fullname\", \"description_length\", \"posts\", \"followers\", \"follows\")\ndatos_testDF[, columnas_intervalo] <- lapply(datos_testDF[, columnas_intervalo], factor)\n\n# Convertir columnas binarias a factor\ncolumnas_binarias <- c(1, 5, 7, 8)\ndatos_testDF[, columnas_binarias] <- lapply(datos_testDF[, columnas_binarias], factor)\n\n# Ver datos_testDF después de la conversión\nhead(datos_testDF)\n```\n\nComo vemos, todas las variables numéricas han pasado a tener datos de intervalo, y todas las columnas han pasado a ser de tipo factor.\n\nAhora toca aplicar las reglas a los datos de test, y realizar la predicción:\n\n```{r}\n# Convertir datos_test a transacciones\nTdatos_test <- as(datos_testDF, \"transactions\")\n\n# Crear una columna vacía para las predicciones\ndatos_testDF$fake_predict_RA <- NA\n\n# Aplicar las reglas a cada transacción en datos_test\nfor (i in 1:length(Tdatos_test)) {\n  # Obtener la transacción de esa fila\n  trans <- Tdatos_test[i]\n  \n  # Evaluar las reglas con el antecedente correspondiente: si el antecedente es subconjunto de la transacción actual, asignar el consecuente de la primera regla que lo cumpla (están ordenadas por confidence) a 'fake_predict_RA'\n  matches <- is.subset(lhs(reglas_fake_verdaderas), trans)\n  \n  # Si alguna regla se cumple, asignar el consecuente correspondiente a 'fake_predict_RA'\n  if (any(matches)) {\n    # Obtener el consecuente de la primera regla que se cumple\n    matching_rule <- reglas_fake_verdaderas[which(matches)[1]]\n    fake_value <- labels(rhs(matching_rule))[1]\n    \n    # Asignar el valor predicho\n    datos_testDF$fake_predict_RA[i] <- sub(\"fake=\", \"\", fake_value)\n  }\n  \n  # Si ninguna regla cuenta con un antecedente que sea subconjunto de la transacción actual, realizar una heurística (árbol de decisión) con las conclusiones extraídas de las reglas\n  else {\n    # Si la cuenta tiene URL externa, es verdadera\n    if (datos_test$external_URL[i] == 1) {\n      datos_testDF$fake_predict_RA[i] <- 0\n      # Si la cuenta no tiene foto de perfil, es falsa\n    } else if (datos_test$profile_pic[i] == 0) {\n      datos_testDF$fake_predict_RA[i] <- 1\n      # Si la cuenta tiene menos de 250 seguido, es falsa\n    } else if (datos_test$followers[i] < 250) {\n      datos_testDF$fake_predict_RA[i] <- 1\n      # En otro caso, consideramos que es verdadera\n    } else {\n      datos_testDF$fake_predict_RA[i] <- 0\n    }\n  }\n}\n```\n\nEchemos un vistazo a las primeras filas de datos_testDF para comprobar que la predicción se ha realizado correctamente:\n\n```{r}\n# Mostrar las primeras filas de datos_testDF\nhead(datos_testDF)\n\n#View(datos_testDF)\n```\n\nVemos que hay predicciones en la columna fake_predict_RA, aunque muchas de ellas (haciendo el View) contienen caracteres '{' y '}'. Deshagámonos de ellos y convirtamos la columna a numérica para poder compararla con la columna fake original:\n\n```{r}\n# Convertir datos_testDF$fake_predict_RA para eliminar los caracteres '{' y '}'\ndatos_testDF$fake_predict_RA <- gsub(\"\\\\{|\\\\}\", \"\", datos_testDF$fake_predict_RA)\n\n# Convertir datos_testDF$fake_predict_RA a numérico\ndatos_testDF$fake_predict_RA <- as.numeric(datos_testDF$fake_predict_RA)\n\n# Mostrar las primeras filas de datos_testDF\nhead(datos_testDF)\n```\n\nMisión cumplida. Ahora, revisemos si hay valores NA en esa columna:\n\n```{r}\n# Contar los valores NA de la columna fake_predict_RA\ncat(\"fake_predict_RA tiene \", sum(is.na(datos_testDF$fake_predict_RA)), \" valores NA.\")\n```\n\nParece que todo va bien. Creemos un nuevo dataset únicamente formado por las predicciones y el valor real de falsedad:\n\n```{r}\ndatos_test_predicciones <- data.frame(fake = fake_originales, fake_predict_RA = datos_testDF$fake_predict_RA)\nView(datos_test_predicciones)\n# Guardar el data frame en un archivo CSV\nwrite.csv(datos_test_predicciones, \"datos_test_predicciones.csv\", row.names = FALSE)\n```\n\nEs momento de calcular el porcentaje de éxito en la predicción de cuentas falsas, verdaderas y en general:\n\n```{r}\n# Contar el número de predicciones correctas cuando la cuenta es falsa\npredicciones_correctas_falsas <- sum(datos_test_predicciones$fake_predict_RA == datos_test_predicciones$fake & datos_test_predicciones$fake == 1)\n\n# Calcular el porcentaje de éxito en la predicción de cuentas falsas\ntotal_falsas <- sum(datos_test_predicciones$fake == 1)\nporcentaje_exito_falsas <- (predicciones_correctas_falsas / total_falsas) * 100\n\n# Contar el número de predicciones correctas cuando la cuenta es verdadera\npredicciones_correctas_verdaderas <- sum(datos_test_predicciones$fake_predict_RA == datos_test_predicciones$fake & datos_test_predicciones$fake == 0)\n\n# Calcular el porcentaje de éxito en la predicción de cuentas verdaderas\ntotal_verdaderas <- sum(datos_test_predicciones$fake == 0)\nporcentaje_exito_verdaderas <- (predicciones_correctas_verdaderas / total_verdaderas) * 100\n\n# Contar el número de predicciones correctas generales\npredicciones_correctas <- sum(datos_test_predicciones$fake_predict_RA == datos_test_predicciones$fake)\n\n# Calcular el porcentaje de éxito general\ntotal_predicciones <- nrow(datos_test_predicciones)\nporcentaje_exito_general <- (predicciones_correctas / total_predicciones) * 100\n\n# Imprimir el resultado\ncat(\"El porcentaje de éxito en la predicción de cuentas falsas es:\", porcentaje_exito_falsas, \"%\\n\", \"El porcentaje de éxito en la predicción de cuentas verdaderas es:\", porcentaje_exito_verdaderas, \"%\\n\", \"El porcentaje de éxito general en la predicción de cuentas es:\", porcentaje_exito_general, \"%\\n\")\n```\n\nComo vemos, los porcentajes de éxito de predicción de la veracidad de la cuenta basados en las reglas de asociación son altos. Podrían mejorarse (especialmente el porcentaje para cuentas verdaderas), pero es un resultado satisfactorio.\n\n```{r}\n# Crear dataset con los porcentajes\nexito_predicciones <- data.frame(tipo = c(\"Reglas de Asociación\"), 'Éxito_cuentas_falsas' = c(porcentaje_exito_falsas), 'Éxito_cuentas_verdaderas' = c(porcentaje_exito_verdaderas), 'Éxito_general' = c(porcentaje_exito_general))\nexito_predicciones\n\n# Guardar el data frame en un archivo CSV\nwrite.csv(exito_predicciones, \"exito_predicciones.csv\", row.names = FALSE)\n```\n\n### ¿Qué patrones encontramos conociendo la veracidad o falsedad de la cuenta?\n\nEn cuanto al objetivo del proyecto, nos importa más el apartado anterior (averiguar las causas que provocan que una cuenta sea verdadera o falsa para poder identificar cuentas falsas según sus parámetros), pero también resulta interesante, al menos, ver las reglas en sentido contrario, es decir, sabiendo que una cuenta es verdadera o falsa, ¿qué valores toman los demás atributos?\n\nNo me detendré a hacer un análisis profundo de este apartado, pero encontremos y observemos las reglas resultantes, comenzando con cuentas falsas:\n\n```{r}\nreglas_fake_lhs <- subset(reglas, subset = lhs %in% \"fake=1\")\nlength(reglas_fake_lhs)\n```\n\n```{r}\ninspect(reglas_fake_lhs)\n```\n\nDestaca la repetida aparición de valores bajos de longitud de la descripción en el consecuente, cuando se combina la falsedad de la cuenta con otros atributos en el antecedente. No extraemos mucha información nueva.\n\nVeamos estas reglas para cuentas verdaderas:\n\n```{r}\nreglas_verdaderas_lhs <- subset(reglas, subset = lhs %in% \"fake=0\")\nlength(reglas_verdaderas_lhs)\n```\n\n```{r}\ninspect(reglas_verdaderas_lhs)\n```\n\nDestaca la repetida aparición en los consecuentes de la presencia de foto de perfil, la ausencia de coincidencia de nombre completo y nombre de usuario y el primer intervalo de valores de los ratios de números en la longitud del username y del fullname.\n\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true,"format-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","output-file":"reglas_asociacion.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.3.450","bibliography":["references.bib"],"editor":"visual","theme":"cosmo","title":"Reglas de Asociación"},"extensions":{"book":{"multiFile":true}}},"pdf":{"identifier":{"display-name":"PDF","target-format":"pdf","base-format":"pdf"},"execute":{"fig-width":5.5,"fig-height":3.5,"fig-format":"pdf","fig-dpi":300,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"pdf","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":true,"merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"pdf-engine":"xelatex","standalone":true,"variables":{"graphics":true,"tables":true},"default-image-extension":"pdf","to":"pdf","output-file":"reglas_asociacion.pdf"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items"},"metadata":{"block-headings":true,"bibliography":["references.bib"],"editor":"visual","documentclass":"scrreprt","title":"Reglas de Asociación"},"extensions":{"book":{"selfContainedOutput":true}}}},"projectFormats":["html","pdf"]}