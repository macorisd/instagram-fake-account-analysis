{"title":"Regresión","markdown":{"yaml":{"title":"Regresión"},"headingText":"Librerías, datasets y procesamiento previo","containsRefs":false,"markdown":"\n\n```{r warning=FALSE, message=FALSE}\nlibrary(readr)\nlibrary(dplyr)\nlibrary(fcaR)\nlibrary(magrittr)\nlibrary(ggplot2)\nlibrary(psych)\nlibrary(arules)\n\ndatos <- read_csv(\"train.csv\")\nView(datos)\ndatos_test <- read_csv(\"test.csv\")\nView(datos_test)\n\ndatos <- rename(datos, profile_pic=`profile pic`, `nums/length_username` = `nums/length username`, fullname_words=`fullname words`, `nums/length_fullname` = `nums/length fullname`, description_length=`description length`, external_URL=`external URL`, posts=`#posts`, followers=`#followers`, follows=`#follows`)\n\ndatos_test <- rename(datos_test, profile_pic=`profile pic`, `nums/length_username` = `nums/length username`, fullname_words=`fullname words`, `nums/length_fullname` = `nums/length fullname`, description_length=`description length`, external_URL=`external URL`, posts=`#posts`, followers=`#followers`, follows=`#follows`)\n```\n\n## Regresión\n\nUna vez visto el Formal Concept Analysis, ahora es el turno de la regresión: analizar la relación entre una variable dependiente (variable objetivo o respuesta) y ciertas variables independientes (variable predictora o explicativa).\n\n### Modelos multi-variable\n\nEn nuestro caso, la variable dependiente será 'fake', y trataremos de encontrar el mejor modelo para explicar la variable dependiente.\n\nPrimero, realicemos un plot de los datos para intentar encontrar relaciones visuales:\n\n```{r}\nplot(datos)\n```\n\nSe observa que, lógicamente, es imposible extraer información visual de la relación entre 'fake' y las demás variables binarias, ya que aparecen 4 puntos en las esquinas (las 4 posibles combinaciones). Sin embargo, las variables numéricas son más reveladoras. Por ejemplo, se nota que en posts y followers hay más cuentas fake cuando estas variables tienen valores bajos.\n\nPodemos osbervar un mejor gráfico quitando las variables binarias:\n\n```{r}\npairs.panels(datos[c(\"profile_pic\",\"nums/length_username\",\"fullname_words\",\"nums/length_fullname\",\"description_length\",\"posts\",\"followers\",\"follows\",\"fake\")])\n```\n\nQueda claro que es necesario un análisis numérico. Comencemos por construir un modelo lineal con todas las variables posibles como independientes:\n\n```{r}\nmodelo1 <- lm(fake ~ .,\n              data = datos)\n\nsummary(modelo1)\n```\n\nAnalicemos la salida:\n\n-   Un intercept de 0,7931 indica que ese es el valor medio de la variable dependiente ('fake') cuando las variables independientes son cero.\n-   profile_pic: es muy significativa, con el valor estimado negativo, es decir, tener una foto de perfil disminuye la probabilidad de ser una cuenta falsa.\n-   nums/length_username: es muy significativa, con un valor estimado de positivo, es decir, un mayor ratio de caracteres numéricos en el nombre de usuario aumenta la probabilidad de ser una cuenta falsa.\n-   fullname_words: es algo significativa, con un valor estimado negativo, es decir, un mayor número de palabras en el nombre completo disminuye ligeramente la probabilidad de ser una cuenta falsa.\n-   nums/length_fullname: no es significativa. Su variación no influye notablemente en la probabilidad de que la cuenta sea falsa.\n-   name==username: es significativa, con un valor estimado positivo, es decir, si el nombre completo y el nombre de usuario son iguales, aumenta la probabilidad de ser una cuenta falsa.\n-   description_length: es muy significativa, con un valor estimado negativo, es decir, una mayor longitud de la descripción disminuye la probabilidad de ser una cuenta falsa.\n-   external_URL: es significativa, con un valor estimado negativo, es decir, tener una URL externa disminuye la probabilidad de ser una cuenta falsa.\n-   private: no es significativa. Su variación no influye notablemente en la probabilidad de que la cuenta sea falsa.\n-   posts: es significativa, con un valor estimado negativo, es decir, un mayor número de publicaciones disminuye la probabilidad de ser una cuenta falsa.\n-   followers: no es significativa. Su variación no influye notablemente en la probabilidad de que la cuenta sea falsa.\n-   follows: no es significativa. Su variación no influye notablemente en la probabilidad de que la cuenta sea falsa.\n\nEsta información nos será útil para la construcción de modelos útiles, que tengan en cuenta las variables más significativas.\n\nProbemos a construir un modelo lineal que deseche las variables no significativas:\n\n```{r}\nmodelo2 <- lm(fake ~ profile_pic + `nums/length_username` + fullname_words + `name==username` + description_length + external_URL + posts, \n              data = datos)\n\nsummary(modelo2)\n```\n\nExpliquemos los resultados generales y la mejora de este modelo con respecto al anterior:\n\n-   Residual Standard Error: el error estándar residual mide la dispersión de los residuos. Una disminución en el segundo modelo (0,316) indica una ligera mejora en la precisión de las predicciones del modelo simplificado.\n-   Multiple R-squared: el R-cuadrado múltiple mide la proporción de la variabilidad en la variable dependiente que es explicada por las variables independientes. Ambos modelos tienen valores similares, con una ligera disminución en el segundo modelo (0,606), lo que indica que se ha perdido ligeramente esa capacidad explicativa de las variables independientes.\n-   Adjusted R-squared: el R-cuadrado ajustado tiene en cuenta el número de variables en el modelo y penaliza la inclusión de variables irrelevantes. El aumento en el R-cuadrado ajustado en el segundo modelo (0,6012) sugiere que el modelo simplificado es más eficiente al explicar la variabilidad de la variable dependiente con menos variables.\n-   F-Statistic: la F-estadística mide la relación entre la variabilidad explicada y la variabilidad no explicada del modelo. Un valor más alto en el segundo modelo (124,8) indica que el modelo simplificado tiene un ajuste global mejor y es más significativo.\n-   p-value: el valor p indica la significancia general del modelo. En ambos casos, el valor p es extremadamente pequeño, lo que significa que ambos modelos son altamente significativos.\n\nProbemos un modelo en el que las variables con mayor nivel de significancia estén al cuadrado:\n\n```{r}\nmodelo3 <- lm(fake ~ I(profile_pic^2) + I(`nums/length_username`^2) + fullname_words + `name==username` + I(description_length^2) + external_URL + posts, \n              data = datos)\n\nsummary(modelo3)\n```\n\nEste modelo es peor que los anteriores en todos los parámetros generales.\n\nProbemos con un modelo lineal cuyas variables independientes son únicamente las 3 que en el primer modelo tenían más significancia:\n\n```{r}\nmodelo4 <- lm(fake ~ profile_pic + `nums/length_username` + description_length, \n              data = datos)\n\nsummary(modelo4)\n```\n\nEste modelo es el mejor por ahora. Ninguno le supera en los parámetros finales, excepto los 2 primeros modelos en el error.\n\nProbemos a elevar al cuadrado las dos variables que, en el primer modelo, eran las más significativas:\n\n```{r}\nmodelo5 <- lm(fake ~ I(profile_pic^2) + I(`nums/length_username`^2) + description_length, \n              data = datos)\n\nsummary(modelo5)\n```\n\nLos resultados empeoran.\n\nParece difícil mejorar el modelo4. Probemos con un modelo que tenga en cuenta únicamente 2 variables más significativas del modelo1, pero sin cuadrados:\n\n```{r}\nmodelo6 <- lm(fake ~ profile_pic + `nums/length_username`, \n              data = datos)\n\nsummary(modelo6)\n```\n\nEl F estadístico mejora, pero los demás parámetros empeoran ligeramente. Aun así, veo este modelo como el mejor, ya que el empeoramiento es muy leve, y el aumento del F estadístico es grande.\n\n### Modelos con una variable independiente (con visualización)\n\nComo acabamos de ver, eliminar variables independientes ha generado buenos resultados. Aunque dudo que encontremos un modelo mejor, aprovechemos para realizar modelos con una única variable independiente (probando con todas ellas y visualizando la predicción).\n\n#### Modelo con profile_pic como variable independiente:\n\n```{r}\nmodelo7 <- lm(fake ~ profile_pic, \n              data = datos)\n\nsummary(modelo7)\n```\n\nEl F estadístico mejora, pero los demás parámetros empeoran considerablemente.\n\nVeamos la predicción:\n\n```{r}\ndatos %>%\n  ggplot(aes(x=profile_pic, y=fake)) + \n  geom_point() + \n  geom_line(aes(x=profile_pic, y=predict(modelo7),\n                color=\"red\"))\n```\n\nSin foto de perfil, hay más probabilidad de que la cuenta sea falsa.\n\n#### Modelo con nums/length_username como variable independiente:\n\n```{r}\nmodelo8 <- lm(fake ~ `nums/length_username`, \n              data = datos)\n\nsummary(modelo8)\n```\n\nVeamos la predicción:\n\n```{r}\ndatos %>%\n  ggplot(aes(x=`nums/length_username`, y=fake)) + \n  geom_point() + \n  geom_line(aes(x=`nums/length_username`, y=predict(modelo8),\n                color=\"red\"))\n```\n\nCon valores bajos de este ratio es menos probable que la cuenta sea falsa.\n\n#### Modelo con fullname_words como variable independiente:\n\n```{r}\nmodelo9 <- lm(fake ~ fullname_words, \n              data = datos)\n\nsummary(modelo9)\n```\n\nVeamos la predicción:\n\n```{r}\ndatos %>%\n  ggplot(aes(x=fullname_words, y=fake)) + \n  geom_point() + \n  geom_line(aes(x=fullname_words, y=predict(modelo9),\n                color=\"red\"))\n```\n\nCon mayores bajos de fullname_words es más probable que la cuenta sea falsa.\n\n#### Modelo con name==username como variable independiente:\n\n```{r}\nmodelo10 <- lm(fake ~ `name==username`, \n              data = datos)\n\nsummary(modelo10)\n```\n\nVeamos la predicción:\n\n```{r}\ndatos %>%\n  ggplot(aes(x=`name==username`, y=fake)) + \n  geom_point() + \n  geom_line(aes(x=`name==username`, y=predict(modelo10),\n                color=\"red\"))\n```\n\nCuando la coincidencia de fullname y username está presente, es más probable que la cuenta sea falsa.\n\n#### Modelo con description_length como variable independiente:\n\n```{r}\nmodelo11 <- lm(fake ~ description_length, \n              data = datos)\n\nsummary(modelo11)\n```\n\nVeamos la predicción:\n\n```{r}\ndatos %>%\n  ggplot(aes(x=description_length, y=fake)) + \n  geom_point() + \n  geom_line(aes(x=description_length, y=predict(modelo11),\n                color=\"red\"))\n```\n\nPara valores altos de description_length es menos probable que la cuenta sea falsa.\n\n#### Modelo con external_URL como variable independiente:\n\n```{r}\nmodelo12 <- lm(fake ~ external_URL, \n              data = datos)\n\nsummary(modelo12)\n```\n\nVeamos la predicción:\n\n```{r}\ndatos %>%\n  ggplot(aes(x=external_URL, y=fake)) + \n  geom_point() + \n  geom_line(aes(x=external_URL, y=predict(modelo12),\n                color=\"red\"))\n```\n\nPara valores 1 de URL externa, es menos probable que la cuenta sea falsa.\n\n#### Modelo con private como variable independiente:\n\n```{r}\nmodelo13 <- lm(fake ~ private, \n              data = datos)\n\nsummary(modelo13)\n```\n\nVeamos la predicción:\n\n```{r}\ndatos %>%\n  ggplot(aes(x=private, y=fake)) + \n  geom_point() + \n  geom_line(aes(x=private, y=predict(modelo13),\n                color=\"red\"))\n```\n\nComo ya señalamos en apartados anteriores, la variable private no determina notablemente si es más o menos probable que la cuenta sea falsa. Este gráfico lo respalda.\n\n#### Modelo con posts como variable independiente:\n\n```{r}\nmodelo14 <- lm(fake ~ posts, \n              data = datos)\n\nsummary(modelo14)\n```\n\nVeamos la predicción:\n\n```{r}\ndatos %>%\n  ggplot(aes(x=posts, y=fake)) + \n  geom_point() + \n  geom_line(aes(x=posts, y=predict(modelo14),\n                color=\"red\"))\n```\n\nPara valores altos de publicaciones es menos probable que la cuenta sea falsa.\n\n#### Modelo con followers como variable independiente:\n\n```{r}\nmodelo15 <- lm(fake ~ followers, \n              data = datos)\n\nsummary(modelo15)\n```\n\nVeamos la predicción:\n\n```{r}\ndatos %>%\n  ggplot(aes(x=followers, y=fake)) + \n  geom_point() + \n  geom_line(aes(x=followers, y=predict(modelo15),\n                color=\"red\"))\n```\n\nPara valores altos de seguidores es menos probable que la cuenta sea falsa.\n\n#### Modelo con follows como variable independiente:\n\n```{r}\nmodelo16 <- lm(fake ~ follows, \n              data = datos)\n\nsummary(modelo16)\n```\n\nVeamos la predicción:\n\n```{r}\ndatos %>%\n  ggplot(aes(x=follows, y=fake)) + \n  geom_point() + \n  geom_line(aes(x=follows, y=predict(modelo16),\n                color=\"red\"))\n```\n\nPara valores altos de cuentas seguidas es menos probable que la cuenta sea falsa.\n\nComo hemos podido observar, las conclusiones extraídas coinciden con las conclusiones que hemos estado viendo en los apartados anteriores. La regresión es un mecanismo muy útil y sencillo para predecir valores esperados, tal y como hemos comprobado.\n\n### Predicción\n\nAhora, es momento de predecir la variable dependiente del dataset de test con el mejor modelo encontrado: modelo6.\n\n```{r}\n# Realizar la predicción con el modelo de regresión modelo6\nprediccion <- predict(modelo6, newdata = datos_test)\nprediccion\n```\n\nComo vemos, hay valores que se salen de los límites de \\[0,1\\], con lo que ajustaremos los valores predichos: \\< 0.5 será 0 y \\>= 0.5 será 1.\n\n```{r}\n# Ajustar los valores predichos: < 0.5 será 0 y >= 0.5 será 1\nfake_predict_regresion <- ifelse(prediccion < 0.5, 0, 1)\n\n# Leer el archivo CSV\ndatos_test_predicciones <- read.csv(\"datos_test_predicciones.csv\")\n\n# Guardar los valores ajustados en una nueva columna de datos_test_predicciones\ndatos_test_predicciones$fake_predict_regresion <- fake_predict_regresion\n\n# Mostrar las primera filas de datos_test_predicciones\nhead(datos_test_predicciones)\n```\n\nAhora, contemos el número de valores NA en la columna fake_predict_regresion:\n\n```{r}\n# Contar el número de valores NA en la columna fake_predict_regresion\ncat(\"La columna fake_predict_regresion tiene \", sum(is.na(datos_test_predicciones$fake_predict_regresion)), \" valores NA\")\n```\n\nParece que la predicción ha sido satisfactoria. Ahora, calculemos el porcentaje de éxito en la predicción de cuentas falsas, de cuentas verdaderas y en general:\n\n```{r}\n# Calcular el porcentaje de éxito en la predicción de cuentas falsas\npredicciones_correctas_falsas_regresion <- sum(datos_test_predicciones$fake_predict_regresion == datos_test_predicciones$fake & datos_test_predicciones$fake == 1)\ntotal_falsas_regresion <- sum(datos_test_predicciones$fake == 1)\nporcentaje_exito_falsas_regresion <- (predicciones_correctas_falsas_regresion / total_falsas_regresion) * 100\n\n# Calcular el porcentaje de éxito en la predicción de cuentas verdaderas\npredicciones_correctas_verdaderas_regresion <- sum(datos_test_predicciones$fake_predict_regresion == datos_test_predicciones$fake & datos_test_predicciones$fake == 0)\ntotal_verdaderas_regresion <- sum(datos_test_predicciones$fake == 0)\nporcentaje_exito_verdaderas_regresion <- (predicciones_correctas_verdaderas_regresion / total_verdaderas_regresion) * 100\n\n# Calcular el porcentaje de éxito general\npredicciones_correctas_regresion <- sum(datos_test_predicciones$fake_predict_regresion == datos_test_predicciones$fake)\ntotal_predicciones_regresion <- nrow(datos_test_predicciones)\nporcentaje_exito_general_regresion <- (predicciones_correctas_regresion / total_predicciones_regresion) * 100\n\n# Guardar el data frame en un archivo CSV\nwrite.csv(datos_test_predicciones, \"datos_test_predicciones.csv\", row.names = FALSE)\n\n# Imprimir el resultado\ncat(\"El porcentaje de éxito en la predicción de cuentas falsas es:\", porcentaje_exito_falsas_regresion, \"%\\n\", \"El porcentaje de éxito en la predicción de cuentas verdaderas es:\", porcentaje_exito_verdaderas_regresion, \"%\\n\", \"El porcentaje de éxito general en la predicción de cuentas es:\", porcentaje_exito_general_regresion, \"%\\n\")\n```\n\nComo vemos, los porcentajes de éxito son altos, lo que indica que el modelo de regresión ha sido efectivo en la predicción de cuentas falsas y verdaderas.\n\nAñadamos los porcentajes de éxito a la tabla de porcentajes:\n\n```{r}\n# Leer el archivo CSV\nexito_predicciones <- read.csv(\"exito_predicciones.csv\")\n\n# Añadir los porcentajes de éxito a la tabla de porcentajes\nexito_predicciones <- rbind(exito_predicciones, c(\"Regresión\", porcentaje_exito_falsas_regresion, porcentaje_exito_verdaderas_regresion, porcentaje_exito_general_regresion))\nexito_predicciones\n\n# Guardar el data frame en un archivo CSV\nwrite.csv(exito_predicciones, \"exito_predicciones.csv\", row.names = FALSE)\n```\n\nLas reglas de asociación han rendido algo mejor que la regresión en la predicción de cuentas falsas, pero la regresión ha sido mejor que las reglas de asociación en la predicción de cuentas verdaderas y en general. En general, la regresión ha sido 6 puntos más efectiva en la predicción general, con respecto a las reglas de asociación.\n\nFCA y regresión han rendido igual de bien en la predicción de cuentas falsas, pero FCA ha sido mejor en la predicción de cuentas verdaderas y en general. En general, FCA ha sido 2,5 puntos más efectiva en la predicción general, con respecto a la regresión.\n\n","srcMarkdownNoYaml":"\n\n```{r warning=FALSE, message=FALSE}\n# Librerías, datasets y procesamiento previo\nlibrary(readr)\nlibrary(dplyr)\nlibrary(fcaR)\nlibrary(magrittr)\nlibrary(ggplot2)\nlibrary(psych)\nlibrary(arules)\n\ndatos <- read_csv(\"train.csv\")\nView(datos)\ndatos_test <- read_csv(\"test.csv\")\nView(datos_test)\n\ndatos <- rename(datos, profile_pic=`profile pic`, `nums/length_username` = `nums/length username`, fullname_words=`fullname words`, `nums/length_fullname` = `nums/length fullname`, description_length=`description length`, external_URL=`external URL`, posts=`#posts`, followers=`#followers`, follows=`#follows`)\n\ndatos_test <- rename(datos_test, profile_pic=`profile pic`, `nums/length_username` = `nums/length username`, fullname_words=`fullname words`, `nums/length_fullname` = `nums/length fullname`, description_length=`description length`, external_URL=`external URL`, posts=`#posts`, followers=`#followers`, follows=`#follows`)\n```\n\n## Regresión\n\nUna vez visto el Formal Concept Analysis, ahora es el turno de la regresión: analizar la relación entre una variable dependiente (variable objetivo o respuesta) y ciertas variables independientes (variable predictora o explicativa).\n\n### Modelos multi-variable\n\nEn nuestro caso, la variable dependiente será 'fake', y trataremos de encontrar el mejor modelo para explicar la variable dependiente.\n\nPrimero, realicemos un plot de los datos para intentar encontrar relaciones visuales:\n\n```{r}\nplot(datos)\n```\n\nSe observa que, lógicamente, es imposible extraer información visual de la relación entre 'fake' y las demás variables binarias, ya que aparecen 4 puntos en las esquinas (las 4 posibles combinaciones). Sin embargo, las variables numéricas son más reveladoras. Por ejemplo, se nota que en posts y followers hay más cuentas fake cuando estas variables tienen valores bajos.\n\nPodemos osbervar un mejor gráfico quitando las variables binarias:\n\n```{r}\npairs.panels(datos[c(\"profile_pic\",\"nums/length_username\",\"fullname_words\",\"nums/length_fullname\",\"description_length\",\"posts\",\"followers\",\"follows\",\"fake\")])\n```\n\nQueda claro que es necesario un análisis numérico. Comencemos por construir un modelo lineal con todas las variables posibles como independientes:\n\n```{r}\nmodelo1 <- lm(fake ~ .,\n              data = datos)\n\nsummary(modelo1)\n```\n\nAnalicemos la salida:\n\n-   Un intercept de 0,7931 indica que ese es el valor medio de la variable dependiente ('fake') cuando las variables independientes son cero.\n-   profile_pic: es muy significativa, con el valor estimado negativo, es decir, tener una foto de perfil disminuye la probabilidad de ser una cuenta falsa.\n-   nums/length_username: es muy significativa, con un valor estimado de positivo, es decir, un mayor ratio de caracteres numéricos en el nombre de usuario aumenta la probabilidad de ser una cuenta falsa.\n-   fullname_words: es algo significativa, con un valor estimado negativo, es decir, un mayor número de palabras en el nombre completo disminuye ligeramente la probabilidad de ser una cuenta falsa.\n-   nums/length_fullname: no es significativa. Su variación no influye notablemente en la probabilidad de que la cuenta sea falsa.\n-   name==username: es significativa, con un valor estimado positivo, es decir, si el nombre completo y el nombre de usuario son iguales, aumenta la probabilidad de ser una cuenta falsa.\n-   description_length: es muy significativa, con un valor estimado negativo, es decir, una mayor longitud de la descripción disminuye la probabilidad de ser una cuenta falsa.\n-   external_URL: es significativa, con un valor estimado negativo, es decir, tener una URL externa disminuye la probabilidad de ser una cuenta falsa.\n-   private: no es significativa. Su variación no influye notablemente en la probabilidad de que la cuenta sea falsa.\n-   posts: es significativa, con un valor estimado negativo, es decir, un mayor número de publicaciones disminuye la probabilidad de ser una cuenta falsa.\n-   followers: no es significativa. Su variación no influye notablemente en la probabilidad de que la cuenta sea falsa.\n-   follows: no es significativa. Su variación no influye notablemente en la probabilidad de que la cuenta sea falsa.\n\nEsta información nos será útil para la construcción de modelos útiles, que tengan en cuenta las variables más significativas.\n\nProbemos a construir un modelo lineal que deseche las variables no significativas:\n\n```{r}\nmodelo2 <- lm(fake ~ profile_pic + `nums/length_username` + fullname_words + `name==username` + description_length + external_URL + posts, \n              data = datos)\n\nsummary(modelo2)\n```\n\nExpliquemos los resultados generales y la mejora de este modelo con respecto al anterior:\n\n-   Residual Standard Error: el error estándar residual mide la dispersión de los residuos. Una disminución en el segundo modelo (0,316) indica una ligera mejora en la precisión de las predicciones del modelo simplificado.\n-   Multiple R-squared: el R-cuadrado múltiple mide la proporción de la variabilidad en la variable dependiente que es explicada por las variables independientes. Ambos modelos tienen valores similares, con una ligera disminución en el segundo modelo (0,606), lo que indica que se ha perdido ligeramente esa capacidad explicativa de las variables independientes.\n-   Adjusted R-squared: el R-cuadrado ajustado tiene en cuenta el número de variables en el modelo y penaliza la inclusión de variables irrelevantes. El aumento en el R-cuadrado ajustado en el segundo modelo (0,6012) sugiere que el modelo simplificado es más eficiente al explicar la variabilidad de la variable dependiente con menos variables.\n-   F-Statistic: la F-estadística mide la relación entre la variabilidad explicada y la variabilidad no explicada del modelo. Un valor más alto en el segundo modelo (124,8) indica que el modelo simplificado tiene un ajuste global mejor y es más significativo.\n-   p-value: el valor p indica la significancia general del modelo. En ambos casos, el valor p es extremadamente pequeño, lo que significa que ambos modelos son altamente significativos.\n\nProbemos un modelo en el que las variables con mayor nivel de significancia estén al cuadrado:\n\n```{r}\nmodelo3 <- lm(fake ~ I(profile_pic^2) + I(`nums/length_username`^2) + fullname_words + `name==username` + I(description_length^2) + external_URL + posts, \n              data = datos)\n\nsummary(modelo3)\n```\n\nEste modelo es peor que los anteriores en todos los parámetros generales.\n\nProbemos con un modelo lineal cuyas variables independientes son únicamente las 3 que en el primer modelo tenían más significancia:\n\n```{r}\nmodelo4 <- lm(fake ~ profile_pic + `nums/length_username` + description_length, \n              data = datos)\n\nsummary(modelo4)\n```\n\nEste modelo es el mejor por ahora. Ninguno le supera en los parámetros finales, excepto los 2 primeros modelos en el error.\n\nProbemos a elevar al cuadrado las dos variables que, en el primer modelo, eran las más significativas:\n\n```{r}\nmodelo5 <- lm(fake ~ I(profile_pic^2) + I(`nums/length_username`^2) + description_length, \n              data = datos)\n\nsummary(modelo5)\n```\n\nLos resultados empeoran.\n\nParece difícil mejorar el modelo4. Probemos con un modelo que tenga en cuenta únicamente 2 variables más significativas del modelo1, pero sin cuadrados:\n\n```{r}\nmodelo6 <- lm(fake ~ profile_pic + `nums/length_username`, \n              data = datos)\n\nsummary(modelo6)\n```\n\nEl F estadístico mejora, pero los demás parámetros empeoran ligeramente. Aun así, veo este modelo como el mejor, ya que el empeoramiento es muy leve, y el aumento del F estadístico es grande.\n\n### Modelos con una variable independiente (con visualización)\n\nComo acabamos de ver, eliminar variables independientes ha generado buenos resultados. Aunque dudo que encontremos un modelo mejor, aprovechemos para realizar modelos con una única variable independiente (probando con todas ellas y visualizando la predicción).\n\n#### Modelo con profile_pic como variable independiente:\n\n```{r}\nmodelo7 <- lm(fake ~ profile_pic, \n              data = datos)\n\nsummary(modelo7)\n```\n\nEl F estadístico mejora, pero los demás parámetros empeoran considerablemente.\n\nVeamos la predicción:\n\n```{r}\ndatos %>%\n  ggplot(aes(x=profile_pic, y=fake)) + \n  geom_point() + \n  geom_line(aes(x=profile_pic, y=predict(modelo7),\n                color=\"red\"))\n```\n\nSin foto de perfil, hay más probabilidad de que la cuenta sea falsa.\n\n#### Modelo con nums/length_username como variable independiente:\n\n```{r}\nmodelo8 <- lm(fake ~ `nums/length_username`, \n              data = datos)\n\nsummary(modelo8)\n```\n\nVeamos la predicción:\n\n```{r}\ndatos %>%\n  ggplot(aes(x=`nums/length_username`, y=fake)) + \n  geom_point() + \n  geom_line(aes(x=`nums/length_username`, y=predict(modelo8),\n                color=\"red\"))\n```\n\nCon valores bajos de este ratio es menos probable que la cuenta sea falsa.\n\n#### Modelo con fullname_words como variable independiente:\n\n```{r}\nmodelo9 <- lm(fake ~ fullname_words, \n              data = datos)\n\nsummary(modelo9)\n```\n\nVeamos la predicción:\n\n```{r}\ndatos %>%\n  ggplot(aes(x=fullname_words, y=fake)) + \n  geom_point() + \n  geom_line(aes(x=fullname_words, y=predict(modelo9),\n                color=\"red\"))\n```\n\nCon mayores bajos de fullname_words es más probable que la cuenta sea falsa.\n\n#### Modelo con name==username como variable independiente:\n\n```{r}\nmodelo10 <- lm(fake ~ `name==username`, \n              data = datos)\n\nsummary(modelo10)\n```\n\nVeamos la predicción:\n\n```{r}\ndatos %>%\n  ggplot(aes(x=`name==username`, y=fake)) + \n  geom_point() + \n  geom_line(aes(x=`name==username`, y=predict(modelo10),\n                color=\"red\"))\n```\n\nCuando la coincidencia de fullname y username está presente, es más probable que la cuenta sea falsa.\n\n#### Modelo con description_length como variable independiente:\n\n```{r}\nmodelo11 <- lm(fake ~ description_length, \n              data = datos)\n\nsummary(modelo11)\n```\n\nVeamos la predicción:\n\n```{r}\ndatos %>%\n  ggplot(aes(x=description_length, y=fake)) + \n  geom_point() + \n  geom_line(aes(x=description_length, y=predict(modelo11),\n                color=\"red\"))\n```\n\nPara valores altos de description_length es menos probable que la cuenta sea falsa.\n\n#### Modelo con external_URL como variable independiente:\n\n```{r}\nmodelo12 <- lm(fake ~ external_URL, \n              data = datos)\n\nsummary(modelo12)\n```\n\nVeamos la predicción:\n\n```{r}\ndatos %>%\n  ggplot(aes(x=external_URL, y=fake)) + \n  geom_point() + \n  geom_line(aes(x=external_URL, y=predict(modelo12),\n                color=\"red\"))\n```\n\nPara valores 1 de URL externa, es menos probable que la cuenta sea falsa.\n\n#### Modelo con private como variable independiente:\n\n```{r}\nmodelo13 <- lm(fake ~ private, \n              data = datos)\n\nsummary(modelo13)\n```\n\nVeamos la predicción:\n\n```{r}\ndatos %>%\n  ggplot(aes(x=private, y=fake)) + \n  geom_point() + \n  geom_line(aes(x=private, y=predict(modelo13),\n                color=\"red\"))\n```\n\nComo ya señalamos en apartados anteriores, la variable private no determina notablemente si es más o menos probable que la cuenta sea falsa. Este gráfico lo respalda.\n\n#### Modelo con posts como variable independiente:\n\n```{r}\nmodelo14 <- lm(fake ~ posts, \n              data = datos)\n\nsummary(modelo14)\n```\n\nVeamos la predicción:\n\n```{r}\ndatos %>%\n  ggplot(aes(x=posts, y=fake)) + \n  geom_point() + \n  geom_line(aes(x=posts, y=predict(modelo14),\n                color=\"red\"))\n```\n\nPara valores altos de publicaciones es menos probable que la cuenta sea falsa.\n\n#### Modelo con followers como variable independiente:\n\n```{r}\nmodelo15 <- lm(fake ~ followers, \n              data = datos)\n\nsummary(modelo15)\n```\n\nVeamos la predicción:\n\n```{r}\ndatos %>%\n  ggplot(aes(x=followers, y=fake)) + \n  geom_point() + \n  geom_line(aes(x=followers, y=predict(modelo15),\n                color=\"red\"))\n```\n\nPara valores altos de seguidores es menos probable que la cuenta sea falsa.\n\n#### Modelo con follows como variable independiente:\n\n```{r}\nmodelo16 <- lm(fake ~ follows, \n              data = datos)\n\nsummary(modelo16)\n```\n\nVeamos la predicción:\n\n```{r}\ndatos %>%\n  ggplot(aes(x=follows, y=fake)) + \n  geom_point() + \n  geom_line(aes(x=follows, y=predict(modelo16),\n                color=\"red\"))\n```\n\nPara valores altos de cuentas seguidas es menos probable que la cuenta sea falsa.\n\nComo hemos podido observar, las conclusiones extraídas coinciden con las conclusiones que hemos estado viendo en los apartados anteriores. La regresión es un mecanismo muy útil y sencillo para predecir valores esperados, tal y como hemos comprobado.\n\n### Predicción\n\nAhora, es momento de predecir la variable dependiente del dataset de test con el mejor modelo encontrado: modelo6.\n\n```{r}\n# Realizar la predicción con el modelo de regresión modelo6\nprediccion <- predict(modelo6, newdata = datos_test)\nprediccion\n```\n\nComo vemos, hay valores que se salen de los límites de \\[0,1\\], con lo que ajustaremos los valores predichos: \\< 0.5 será 0 y \\>= 0.5 será 1.\n\n```{r}\n# Ajustar los valores predichos: < 0.5 será 0 y >= 0.5 será 1\nfake_predict_regresion <- ifelse(prediccion < 0.5, 0, 1)\n\n# Leer el archivo CSV\ndatos_test_predicciones <- read.csv(\"datos_test_predicciones.csv\")\n\n# Guardar los valores ajustados en una nueva columna de datos_test_predicciones\ndatos_test_predicciones$fake_predict_regresion <- fake_predict_regresion\n\n# Mostrar las primera filas de datos_test_predicciones\nhead(datos_test_predicciones)\n```\n\nAhora, contemos el número de valores NA en la columna fake_predict_regresion:\n\n```{r}\n# Contar el número de valores NA en la columna fake_predict_regresion\ncat(\"La columna fake_predict_regresion tiene \", sum(is.na(datos_test_predicciones$fake_predict_regresion)), \" valores NA\")\n```\n\nParece que la predicción ha sido satisfactoria. Ahora, calculemos el porcentaje de éxito en la predicción de cuentas falsas, de cuentas verdaderas y en general:\n\n```{r}\n# Calcular el porcentaje de éxito en la predicción de cuentas falsas\npredicciones_correctas_falsas_regresion <- sum(datos_test_predicciones$fake_predict_regresion == datos_test_predicciones$fake & datos_test_predicciones$fake == 1)\ntotal_falsas_regresion <- sum(datos_test_predicciones$fake == 1)\nporcentaje_exito_falsas_regresion <- (predicciones_correctas_falsas_regresion / total_falsas_regresion) * 100\n\n# Calcular el porcentaje de éxito en la predicción de cuentas verdaderas\npredicciones_correctas_verdaderas_regresion <- sum(datos_test_predicciones$fake_predict_regresion == datos_test_predicciones$fake & datos_test_predicciones$fake == 0)\ntotal_verdaderas_regresion <- sum(datos_test_predicciones$fake == 0)\nporcentaje_exito_verdaderas_regresion <- (predicciones_correctas_verdaderas_regresion / total_verdaderas_regresion) * 100\n\n# Calcular el porcentaje de éxito general\npredicciones_correctas_regresion <- sum(datos_test_predicciones$fake_predict_regresion == datos_test_predicciones$fake)\ntotal_predicciones_regresion <- nrow(datos_test_predicciones)\nporcentaje_exito_general_regresion <- (predicciones_correctas_regresion / total_predicciones_regresion) * 100\n\n# Guardar el data frame en un archivo CSV\nwrite.csv(datos_test_predicciones, \"datos_test_predicciones.csv\", row.names = FALSE)\n\n# Imprimir el resultado\ncat(\"El porcentaje de éxito en la predicción de cuentas falsas es:\", porcentaje_exito_falsas_regresion, \"%\\n\", \"El porcentaje de éxito en la predicción de cuentas verdaderas es:\", porcentaje_exito_verdaderas_regresion, \"%\\n\", \"El porcentaje de éxito general en la predicción de cuentas es:\", porcentaje_exito_general_regresion, \"%\\n\")\n```\n\nComo vemos, los porcentajes de éxito son altos, lo que indica que el modelo de regresión ha sido efectivo en la predicción de cuentas falsas y verdaderas.\n\nAñadamos los porcentajes de éxito a la tabla de porcentajes:\n\n```{r}\n# Leer el archivo CSV\nexito_predicciones <- read.csv(\"exito_predicciones.csv\")\n\n# Añadir los porcentajes de éxito a la tabla de porcentajes\nexito_predicciones <- rbind(exito_predicciones, c(\"Regresión\", porcentaje_exito_falsas_regresion, porcentaje_exito_verdaderas_regresion, porcentaje_exito_general_regresion))\nexito_predicciones\n\n# Guardar el data frame en un archivo CSV\nwrite.csv(exito_predicciones, \"exito_predicciones.csv\", row.names = FALSE)\n```\n\nLas reglas de asociación han rendido algo mejor que la regresión en la predicción de cuentas falsas, pero la regresión ha sido mejor que las reglas de asociación en la predicción de cuentas verdaderas y en general. En general, la regresión ha sido 6 puntos más efectiva en la predicción general, con respecto a las reglas de asociación.\n\nFCA y regresión han rendido igual de bien en la predicción de cuentas falsas, pero FCA ha sido mejor en la predicción de cuentas verdaderas y en general. En general, FCA ha sido 2,5 puntos más efectiva en la predicción general, con respecto a la regresión.\n\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true,"format-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","output-file":"regresion.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.3.450","bibliography":["references.bib"],"editor":"visual","theme":"cosmo","title":"Regresión"},"extensions":{"book":{"multiFile":true}}},"pdf":{"identifier":{"display-name":"PDF","target-format":"pdf","base-format":"pdf"},"execute":{"fig-width":5.5,"fig-height":3.5,"fig-format":"pdf","fig-dpi":300,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"pdf","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":true,"merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"pdf-engine":"xelatex","standalone":true,"variables":{"graphics":true,"tables":true},"default-image-extension":"pdf","to":"pdf","output-file":"regresion.pdf"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items"},"metadata":{"block-headings":true,"bibliography":["references.bib"],"editor":"visual","documentclass":"scrreprt","title":"Regresión"},"extensions":{"book":{"selfContainedOutput":true}}}},"projectFormats":["html","pdf"]}